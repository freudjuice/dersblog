\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Uzaklýklar, Norm, Benzerlik

Literatürdeki anlatým norm ve uzaklýk konusu etrafýnda biraz kafa karýþýklýðý
yaratabiliyor, bu yazýda biraz açýklýk getirmeye çalýþalým. Norm bir büyüklük
ölçüsüdür. Vektör uzaylarý ile olan alakasýný görmek için {\em Fonksiyonel
  Analiz} notlarýna bakýlabilir. Büyüklük derken bir $x$ vektörünün
büyüklüðünden bahsediyoruz, ki bu çoðunlukla $||x||$ gibi bir kullanýmda
görülür, eðer altsimge yok ise, o zaman 2 kabul edilir, yani $||x||_2$. Bu ifade
bir L2 norm'unu ifade eder. $||x||_1$ varsa L1 norm'ü olurdu.

L1,L2 normalarý, ya da genel olarak $p$ üzerinden $L_p$ normlarý þöyle gösterilir,

$$ ||x||_p = (\sum_i |x_i|^p)^{1/p} $$

ki $x_i$, $x$ vektörü içindeki öðelerdir. Eðer $p=2$ ise, L2 norm

$$ ||x||_2 = \bigg(\sum_i |x_i|^2 \bigg)^{1/2} $$

Üstel olarak $1/2$'nin karekök demek olduðunu hatýrlayalým, yani 

$$ ||x||_2 = \sqrt{\sum |x_i|^2} $$

Bu norm ayrýca Öklitsel (Euclidian) norm olarak ta bilinir, tabii ki bunun
Öklitsel uzaklýk ile yakýn baðlantýsý var (iki vektörü birbirinden çýkartýp
Öklit normunu alýrsak Öklit uzaklýðýný hesaplamýþ oluruz).

Eðer $p=1$ olsaydý, yani L1 norm, o zaman üstel olarak $1/1$ olur, yani hiçbir
üstel / köksel iþlem yapýlmasýna gerek yoktur, iptal olurlar,

$$ ||x||_1 = \sum |x_i|^2 $$

Örnek

$$ 
a = \left[\begin{array}{r}
3 \\ -2 \\ 1
\end{array}\right]
 $$

$$ ||a|| = \sqrt{3^2+(-2)^2+1^2} = 3.742 $$

Örnekte altsimge yok, demek ki L2 norm. 

Ek Notasyon, Ýþlemler

L1 normu için yapýlan iþlemi düþünelim, vektör öðeleri kendileri ile
çarpýlýyor ve sonuçlar toplanýyor. Bu iþlem

$||x||_1 = x^Tx$

olarak ta gösterilemez mi? Ya da $x \cdot x$ olarak ki bu noktasal çarpýmdýr.

Bazen de yapay öðrenim literatüründe $||x||^2$ þekilde bir kullaným
görebiliyorsunuz. Burada neler oluyor? Altsimge yok, demek ki L2
norm. Sonra L2 normun karesi alýnmýþ, fakat L2 normu tanýmýna göre bir
karekök almýyor muydu? Evet, fakat o zaman kare iþlemi karekökü iptal eder,
demek ki L2 normunun karesini almak bizi L1 normuna döndürür! Eh bu normu
da $x^Tx$ olarak hesaplayabildiðimize göre hemen o notasyona geçebiliriz,
demek ki $||x||^2 = x^Tx = x \cdot x$. 

Ýkisel Vektörlerde Benzerlik

Diðer ilginç bir kullaným ikisel deðerler içeren iki vektör arasýnda
çakýþan 1 deðerlerinin toplamýný bulmak. Mesela 

\begin{minted}[fontsize=\footnotesize]{python}
a = np.array([1,0,0,1,0,0,1,1])
b = np.array([0,0,1,1,0,1,1,0])
\end{minted}

Bu iki vektör arasýndaki 1 uyusumunu bulmak için noktasal çarpým yeterli,
çünkü 1 ve 0, 0 ve 1, 0 ve 0 çarpýmý sýfýr verir, ama 1 çarpý 1 = 1
sonucunu verir. O zaman L1 norm bize ikisel iki vektör arasýnda kabaca bir
benzerlik fikri verebilir.

\begin{minted}[fontsize=\footnotesize]{python}
print np.dot(a,b)
\end{minted}

\begin{verbatim}
2
\end{verbatim}

Matris Normlarý

Vektörlerin norm'ü hesaplanabildiði gibi matris norm'ü da hesaplanabilir. Bir
$A$ matrisi için matris norm'ü

$$ || A || = \sup \{ ||Ax|| : x \in \mathbb{R}^n, ||x||=1 \textrm{ olacak þekilde } \} $$

Bazen þöyle de gösterilir,

$$  || A || = \sup_{||x||=1} \{ ||Ax|| \} $$

ya da

$$ || A || = \sup \{ \frac{||Ax||}{||x||} : x \in \mathbb{R}^n, x \ne 0 \textrm{ olacak þekilde } \} $$

Daha genel formda p-norm'u

$$ || A || = \sup
\bigg\{
\frac{||Ax||_p}{||x||_p} : x \in \mathbb{R}^n, x \ne 0 \textrm{ olacak þekilde }
\bigg\} $$

Özel durum $p=2$ için ki bu yine, vektörler için olduðu gibi, Öklitsel norm
olarak biliniyor. Bu durumda $A$'nýn normu $A$'nýn en büyük eþsiz
deðeridir. Yaklaþýk olarak hesaplama açýsýndan þunu da verelim,

$$ ||A||_1 = \max_{1 \le j \le n} \sum _{i=1}^{m} |a_{ij}| $$

Yani tüm matris kolonlarýnýn hücrelerinin mutlak deðerleri toplanýyor, bu
toplamlar arasýnda en büyük sayýyý veren kolonun toplamý normun yaklaþýk
deðeridir.

\newpage

$$ (x-v)^TA(x-v) < 1 $$

Üstteki formülde $x$ yerine $Px$ geçirirsek, ki $P$ herhangi bir matris,
eþitsizliðin sol tarafýna ne olur?

$$ (P(x-v))^T A (P(x-v))$$

$$ (x-v)^T P^T A P (x-v)  $$

Bu formüle bir þekilde ulaþmamýz lazým. Ama nasýl? Basitleþtirme amaçlý olarak
$w = x-v$ tanýmlayalým, ki $x \ne v$ olacak þekilde. $X = \frac{1}{||w||^2} I$
tanýmlayalým, bu bir köþegen matris, köþegeninde $1/||w||^2$ deðerleri var. Bu
sayede

$$ w^T A W < 1  \Rightarrow w^T A W < w^T X w  $$

1 yerine üstteki en saðdaki terimi kullanmýþ olduk. Herhangi bir $x$ için
üstteki eþitsizlik her $w$ için doðru olacaktýr. Bu da $A - X$ negatif kesin
demektir (pozitif kesinliðin tersi), o zaman þunu da söyleyebiliriz,

$$ A - X < 0 \Rightarrow P^T(A-x)P < 0 \Rightarrow P^T AP < P^TXP $$

Soldan ve saðdan $w^T,w$ ile çarparsak,

$$ w^T P^T AP w < w^T P^TXP w = \frac{1}{||w||^2} w^T P^T P w = (Pu)^T Pu$$

ki $u = \frac{w}{||w||}$ $x-v$ yönünü gösteren birim vektördür. 

Þimdi matris normunun ne olduðunu hatýrlayalým,

$$ ||P|| = \sup_{||u||=1} || Pu || $$

O zaman emin bir þekilde diyebiliriz ki 

$$ (x-v)^TA(x-v) < 1 \Rightarrow (x-v)^T P^T A P (x-v) < ||P||^2 $$


\newpage

Kaynaklar

[1] Marmer, {\em Economics 627 Econometric Theory II, Vector and Matrix Differentiation}, \url{http://faculty.arts.ubc.ca/vmarmer/econ627/}
        
[2] Duda, Hart, {\em Pattern Classification}

[4] Bishop, {\em Pattern Recognition and Machine Learning}

[5] Wikipedia, {\em Matrix norm}, \url{https://en.wikipedia.org/wiki/Matrix_norm}

\newpage 

Sherley-Morrison Formülü

Bu formulun temeli su esitlikten basliyor [1, sf. 124],

$$
(I+cd^T)^{-1} = I - \frac{cd^T}{1+dc^T}
$$

Esitligin dogru oldugunu kontrol icin iki tarafi $(I+cd^T)$ ile
carpabiliriz, eger sag tarafta birim matrisi elde edersek esitlik dogru
demektir,

$$
I + cd^T - \frac{cd^T (I + cd^T)}{1+d^Tc}
$$

$$
= I + cd^T - \frac{I cd^T (1+cd^T)}{1+d^Tc}
$$

$$
= I + cd^T - cd^T = I
$$

Eðer sýfýrdan baþlayarak türetmek istesek, öyle bir $\alpha$ arýyoruz ki
$(I + cd^T)$ ifadesini $(I + \alpha cd^T)$ ile çarpýnca bize birim matrisi
versin. Çarpýmý yaparsak,

$$
(I + cd^T) (I + \alpha cd^T) = I + cd^T + \alpha cd^T + \alpha cd^Tcd^T 
$$

$$
= I + (1 + \alpha + \alpha d^T c) cd^T
$$

Üsttekinin birim matrisi $I$ olmasý için $1 + \alpha + \alpha d^T c$ sýfýr
olmalý, onun sýfýr olmasý için de

$$\alpha = \frac{-1}{1 + d^Tc}$$

doðru olmalý. $\alpha$'yi yerine koyarsak, 

$$
(I + \alpha cd^T) = I - \frac{cd^T}{1+dc^T}
$$

elde ederiz, yani $(I + \alpha cd^T)^{-1}$ açýlýmý budur. 

Kaynaklar 

[1] Meyer, {\em Matrix Analysis and Applied Linear Algebra}

[2] Gadzinski, {How to Derive the Sherman-Morrison Base Formula, Math Stackexchange Sorusuna Cevap}, 
    \url{https://math.stackexchange.com/a/3462542/6786}

\newpage 

Yunan Harfleri

\includegraphics[width=30em]{../../algs/zapp/letters.png}

\end{document}
