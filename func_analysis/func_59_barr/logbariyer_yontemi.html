<h1>Log-Bariyer Yöntemi</h1>
<!DOCTYPE html>
<html>
  <head>
    <title>Log-Bariyer Yöntemi
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
</script>
</head>

<p>[Newton yöntemi özeti atlandı]</p>
<p>Şimdiye kadar kısıtlanmamış Newton yönteminden bahsettik [1, 53:18]. Şimdi
lineer olarak kısıtlanmış, $Ax=b$ ile, olan duruma bakalım, çünkü ileride
faydalı olacak.</p>
<p>En bariz yaklaşım $Ax=b$'nin bir doğrusal (affine) uzay yaratması, ve
optimizasyonun bu daha ufak uzayda iş yapması. Bir değişken değişimi
yaparız, $x = Fy + x_0$, ki $F$, $A$'nin sıfır uzayını kapsıyor, ardından
optimizasyon problemini $y$ bazlı bir probleme indirge. Bu yaklaşıma
"indirgenmiş uzay yaklaşımı" deniyor. Tarif edilen gayet doğal, basit bir
yaklaşım aslında, fakat bir bedeli de var. Eğer orijinal problem seyrek ise
değişim sonrası çok miktarda yapı kaybı (yaı seyreklik) olacak.</p>
<p>Bir diğer seçenek eşitlikle kısıtlanmış Newton (equality constrained
Newton). Bu yöntemle $x^+ = x + t v$ adımında $v$ karesel
yaklaşıksallamanın çözümü, fakat bu çözüm sınırlanmış bir problemin çözümü,
bir sonraki $x^+$'yi olurlu halde tutacak bir sınırlama bu.</p>
<p>Çözülen problem </p>
<p>$$
v = \arg\min_{Az = 0} \nabla f(x)^T (z-x) + \frac{1}{2} (z-x)^T \nabla^2 f(x)(z-x)
$$</p>
<p>Üstteki $x^+$'i olurlu kümede tutar çünkü </p>
<p>$$
Ax^+ = Ax + tAv = b + 0 = b
$$</p>
<p>KKT koşulları üzerinden çözüm</p>
<p>$$
\left[\begin{array}{cc}
\nabla^2 f(x) &amp; A^T \\
A &amp; 0
\end{array}\right]
\left[\begin{array}{c}
v \\
w
\end{array}\right] = 
- 
\left[\begin{array}{c}
\nabla f(x) \\
Ax - b
\end{array}\right]
$$</p>
<p>ile belirtilebilir. KKT bölümünde karesel problem örneğindeki gördüğümüz
$Q$ burada $\nabla^2 f(x)$ oluyor, atılan adım sonrası gelinen yerin ne
olacağı da kısıtlama içinde görülebilir.</p>
<p>Olurlu noktadan basliyorsak, ozel durum $Ax = b$, tabii o zaman </p>
<p>$$
\left[\begin{array}{cc}
\nabla^2 f(x) &amp; A^T \\
A &amp; 0
\end{array}\right]
\left[\begin{array}{c}
v \\
w
\end{array}\right] = 
- 
\left[\begin{array}{c}
\nabla f(x) \\
0
\end{array}\right]
$$</p>
<p>O zaman bariyer metotu nedir? Bu metotla yine Newton metotunu uzatacağız,
ve eşitsizlik olan problemlerle uğraşacağız. </p>
<p>$$
\min_x f(x) \quad \textrm{oyle ki}
$$
$$
Ax = b
$$
$$
h_i(x) \le 0, \quad i=1,..,m
$$</p>
<p>Kriter dışbükey, sınırlamalar lineer, ve dışbükey eşitsizlik
sınırlamaları, $h_i(x) \le 0$ ile.</p>
<p>Bariyer metotu eşitsizliklerle başetmenin bir yolu. Eşitsizlik içeren
programların en büyük problemi sınırlarda ne yapılacağına karar vermek,
yani olurlu kümenin sınırlarında. Başetmek için olurlu küme 
$C \equiv { x: h_i(x) \le 0 , i=1,..,m}$ </p>
<p>$$
\min_x f(x) + I_C(x)
$$
$$
Ax = b
$$</p>
<p>ile kritere dahil edilir, ki $I_C$ göstergeç fonksiyonudur. Ana fikir sınır
noktalarında işler zorlaşıyorsa niye oralardan uzak durmuyoruz? Fakat
göstergeç fonksiyonu ile çalışmak zor, onu da yaklaşıksal olarak temsil
ederiz, işte bariyer fonksiyonu budur. Öyle bir fonksiyon seçeriz ki
sınırlarda aşırı büyük değerler vererek bizi minimizasyon bağlamında
oralardan "geri iter". Sanki sınırlara bir manyetik alan koyuyoruz,
oralara yaklaşınca geri itiliyoruz. </p>
<p>Tabii bir yandan Newton metotu da kullanabilmek istiyoruz, ideal olarak
pürüzsüz bir metot olursa elimizde iyi olur. Log bariyer fonksiyonu böyle
bir fonksiyon</p>
<p>$$
\phi(x) = -\sum_{i=1}^{m} \log(-h_i(x))
\qquad (1)
$$</p>
<p>Böylece ana problemi şu hale getirebiliriz,</p>
<p>$$
\min_x f(x) + \frac{1}{t} \phi(x) \quad \textrm{öyle ki}
$$
$$
Ax = b
$$</p>
<p>ki $t&gt;0$. Görülen $1/t$ dışarıdan bizim tanımladığımız bir parametre,
optimizasyonu ayarlamak için kullanıyoruz onu. Eğer $t$ küçükse, sıfıra
yakınsa o zaman bariyer baskın haldedir (daha büyüktür), tabii o zaman
sınırlardan kaçmak optimizasyon için daha önemli hale gelir. Eğer $t$'yi
büyütürsek bu "orijinal kriter $f$'ye daha fazla önem ver" demektir.</p>
<p>Dersin geri kalanında üstteki format yerine alttaki ile çalışacağız,
üstteki ile aynı, </p>
<p>$$
\min_x t f(x) + \phi(x) \quad \textrm{öyle ki}
$$
$$
Ax = b
\qquad (2)
$$</p>
<p>Log-Bariyer Calculus</p>
<p>(1) için türev</p>
<p>$$
\nabla \phi(x) = - \sum_{i=1}^{m} \frac{1}{h_i(x)} \nabla h_i(x)
$$</p>
<p>Hessian</p>
<p>$$
\nabla^2 \phi(x) = 
\sum _{i=1}^{m} \nabla h_i(x) \nabla h_i(x)^T - 
\sum _{i=1}^{m} \frac{1}{h_i(x)} \nabla^2 h_i(x)
$$</p>
<p>Örnek</p>
<p>Pek çok yerde kullanılan bir eşitsizlik görelim, mesela bütün $x_i &lt; 0$
olduğu bir durum, yani $h_i(x) = -x$. O zaman bariyer neye benzer? </p>
<p>$$
\phi(x) = - \sum _{i=1}^{n} \log x_i
$$</p>
<p>$$
\nabla \phi(x) = 
- \left[\begin{array}{c}
1/x_1  \\ 
\vdots \\
1/x_n
\end{array}\right] 
= - X^{-1} \textbf{1} 
$$</p>
<p>Burada $X$ matrisi </p>
<p>$$
X = \mathrm{diag}(x) = 
\left[\begin{array}{ccc}
x_1 &amp; &amp; \\
    &amp; \ddots &amp; \\
    &amp; &amp; x_n
\end{array}\right]
$$</p>
<p>ve $\textbf{1}$ sembolu tamamen 1'lerden oluşan matris. </p>
<p>Hessian</p>
<p>$$
\nabla^2 \phi (x) = \left[\begin{array}{ccc}
1/x_1^2 &amp; &amp; \\
    &amp; \ddots &amp; \\
    &amp; &amp; 1/x_n^2
\end{array}\right] = X^2 
$$</p>
<p>Problemi yaklaşık olarak temsil ettik. Uygun şartlarda problem (2)'nin
çözümü vardır. Neden olduğunu görmek zor değil, $\phi$ beni sınırlardan
uzak tutar, ve hedefim $f$'ye ulaşırım, lineer diğer sınırları dikkate
alarak tabii. Gidis yolu neye benzerdi?</p>
<p>Eğer problemim $\min c^T x$ öyle ki $D x \le e$ olsaydı,</p>
<p><img alt="" src="func_59_barr_01.png" /></p>
<p>Sınırlar görülüyor, başlangıç o sınırların ortasında diyelim, ufak $t$
olduğu zaman oradayım, çünkü sınırlar kuvvetli şekilde bizi her taraftan
itiyor. Nihai sonuç $x^*$ iki sınırın kesiştiği yerde görülüyor. 
$t$'yi arttırdıkça $f$'nin önemi artacak, ve sonuca yaklaşacağız.</p>
<p>Merkezi gidiş yolu, (1) için KKT koşulları üzerinden gösterilebilir?  Bu
yol (1) probleminin $t$ üzerinden fonksiyon haline getirilmiş
çözümüdür. Her $t$ için (1)'i çözebilirim, çözüme $x^*(t)$ derim, ve
$x^*$'ye $t$'nin bir fonksiyonu olarak bakınca, bariyer metot çerçevesinde,
ortaya çıkan çözüm serisine merkezi gidiş yolu denir. Her $t$ için (1)'in
çözümünü KKT koşulları üzerinden temsil edebilirim, böylece her adımda
$x^*(t)$'nin optimal olması için ne gerekir sorusunu formülize etmiş
oluyorum.  Önce KKT ana olurluk şartları</p>
<p>$$
A x^* = b, \quad h_i(x^*(t)) \le 0
$$</p>
<p>Geri kalanlar, Lagrangian üzerinden </p>
<p>$$
t f(x) + \phi(x) + w^T (Ax - b)
$$</p>
<p>Bu Lagrangian'in $x$ üzerinden gradyanını alıp sıfıra eşitlersem durağanlık
şartını elde ediyorum. </p>
<p>$$
t \nabla f(x^*(t)) - \sum_{i=1}^{m} \frac{1}{h_i(x^* (t))} 
\nabla h_i(x^*(t)) + A^T w = 0
$$</p>
<p>Gradyan kullanmak yeterli çünkü tüm fonksiyonlar dışbükey ve pürüzsüz. </p>
<p>Üstteki problemi bazı herhangi bir $w$ için çözebilirsem o zaman merkezi
gidiş yolundaki bir çözümü her $t$ için karakterize etmiş oldum. Umudumuz o
ki $t$'yi sonsuzluğa doğru iterken gördüğümüz KKT koşullarının ima ettiği
çözümler orijinal problemdeki sonuçlara yaklaşsın. Çünkü bariyer
fonksiyonunu $1/t$ ile çarptım ve $t$'yi büyüttükçe çarpım gösterge
fonksiyonuna yaklaşacaktır, o zaman optimizasyonu yaparken $t$'yi
büyüttükçe orijinal problemin gerçek sonucuna yaklaşmış olalım. </p>
<p>[devam edecek]</p>
<p>Kaynaklar</p>
<p>[1] Tibshirani, <em>Convex Optimization, Lecture Video 14</em>, 
<a href="https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg">https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg</a>   </p>
<p>[2] Tibshirani, <em>Convex Optimization, Lecture Video 15</em>, 
<a href="https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg">https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg</a>   </p>