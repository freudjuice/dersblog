<h1>Autograd ile Optimizasyon</h1>
<!DOCTYPE html>
<html>
  <head>
    <title>Autograd ile Optimizasyon
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
</script>
</head>

<p>Otomatik türevin nasıl işlediğini [1] yazısında gördük. Programlama dilinde
yazılmış, içinde <code>if</code>, <code>case</code>, hatta döngüler bile içerebilen
herhangi bir kod parçasının türevini alabilmemizi sağlayan otomatik türev
almak pek çok alanda işimize yarar. Optimizasyon alanı bunların başında
geliyor. Düşünürsek, eğer sembolik olarak türev alması çok çetrefil bir
durum varsa, tasaya gerek yok; bir fonksiyonu kodlayabildiğimiz anda onun
türevini de alabiliriz demektir.</p>
<p>Önce bazı genel optimizasyon konularını işleyelim. </p>
<p>Sınırlanmamış optimizasyonda (unconstrained optimization) $f(x)$
fonksiyonunu minimum değerde tutacak $x$ değerini bulmaya uğraşıyoruz, ki
$x$ tek boyutlu skalar, ya da çok boyutlu $x \in \mathbb{R}^n$
olabilir. Yani yapmaya uğraştığımız</p>
<p>$$
\min_x f(x)
$$</p>
<p>işlemi. Peki minimumu nasıl tanımlarız? Bir nokta $x^*$ global minimize
edicidir eğer tüm $x$'ler için $f(x^*) \le f(x)$ ise, ki
$x \in \mathbb{R}^n$, en azından $x$ modelleyeni ilgilendiren tüm küme
öğeleri için.</p>
<p>Fakat çoğu zaman bir global $f$'i kullanmak mümkün olmayabilir, fonksiyon
çok çetrefil, çok boyutlu, bilinmez durumdadır, ve elimizde sadece yerel
bilgi vardır. Bu durumda üstteki tanımı "bir $N$ bölgesi içinde" olacak
şekilde değiştiririz ki bölge, $x^*$ etrafındaki, yakınındaki bölgedir.</p>
<p>Üstteki tanımı okuyunca  $x^*$'in yerel minimum olup olmadığını anlamanın
tek yolunun yakındaki diğer tüm noktalara teker teker bakmak olduğu anlamı
çıkabilir, fakat eğer $f$ pürüzsüz bir fonksiyon ise yerel minimumu
doğrulamanın çok daha hızlı bir yöntemi vardır. Hatta ve hatta eğer
fonksiyon $f$ iki kez türevi alınabilir haldeyse $x^*$'in yerel minimum
olduğunu ispatlamak daha kolaylaşır, $\nabla f(x^*)$ ve Hessian $\nabla^2
f(x^*)$'e bakarak bunu yapabiliriz.</p>
<p>Minimallik için 1. ve 2. derece şartlar var. 1. derece gerekli şart (ama
yeterli değil) $\nabla f = 0$ olması. Bu standard Calculus'tan bildiğimiz
bir şey, minimum ya da maksimumda birinci türev sıfırdır. Ama türevin sıfır
olup minimum ya da maksimum olmadığı durum da olabilir, mesela
$f(x) = x^3$. $f'(0) = 0$'dir fakat $x=0$ ne maksimum ne de
minimumdur. Daha iyi bir termioloji $\nabla f = 0$ noktalarını {\em kritik
  nokta} olarak tanımlamaktır. $x=0$ noktasında bir değişim oluyor, bu
değişim kritik bir değişim, her ne kadar minimum ya da maksimum olmasa da.</p>
<pre><code class="python">x = np.linspace(-3,3,100)
plt.plot(x,x**3)
plt.grid(True)
plt.savefig('func_40_autograd_01.png')
</code></pre>

<p><img alt="" src="func_40_autograd_01.png" /></p>
<p>Bir kritik noktanın yerel maksimum ya da yerel minimum olup olmadığını
anlamak için fonksiyonun ikinci türevine bakabiliriz. Bir
$f: \mathbb{R}^n \to \mathbb{R}$ var ve $x^*$ noktasının kritik nokta
olduğunu düşünelim, yani $\nabla f(x^*) = 0$. Şimdi çok ufak bir $h$ adımı
için $f(x^* + h)$'a ne olduğuna bakalım. Burada Taylor açılımı
kullanabiliriz [2], </p>
<p>$$
f(x + h^*) = 
f(x^*) + \nabla f(x^*) h + 
\frac{1}{2} h^T f(x^*) \nabla^2 (x^*) f(x^*) h + 
O(3)
$$</p>
<p>$\nabla^2 (x^*)$ bir matristır içinde $f$'nin ikinci derece türevleri
vardır [6]. Şimdi, kritik noktada olduğumuz için $\nabla f(x^*) = 0$, ve
$O(3)$ terimlerini iptal edersek, üstteki</p>
<p>$$
f(x^* + h^*) - f(x^*) = \frac{1}{2} h^T \nabla^2 (x^*)  h + O(3)
$$</p>
<p>haline gelir. Simdi "bir noktanın mesela yerel maksimum olması" sözünü
$f(x^* + h^*) - f(x^*) &lt; 0$ ile ifade edebiliriz, çünkü $x^*$ etrafındaki
tüm $x$'lerin $f$'in daha az değerlerinden olma şartını aramış oluyoruz
(adım atılıyor, çıkartma yapılıyor, sonuç sıfırdan küçük). Tabii bu "tüm"
söylemi yaklaşıksal, o sebeple minimumluk ifadesi <em>yerel</em>.</p>
<p>Devam edersek $f(x^* + h^*) - f(x^*) &lt; 0$ olması şartı aynı zamanda
$\frac{1}{2} h^T \nabla^2 (x^*) h &lt; 0$ anlamına gelir, bu da
$\nabla^2 (x^*)$ negatif kesin demektir. Çünkü $A$ simetrik bir matris
olduğu zaman</p>
<p>$x^TAx &lt; 0$ ise matris negatif kesin</p>
<p>$x^TAx \le 0$ ise matris negatif yarı-kesin (negatif semi-definite)</p>
<p>$x^TAx &gt; 0$ ise matris pozitif kesin</p>
<p>$x^TAx \ge 0$ ise matris pozitif yarı-kesin (positive semi-definite)</p>
<p>Gradyan Inisi</p>
<p>Optimizasyonun mekaniğine gelelim. Diyelim ki basit, tek boyutlu bir $f(x)
= x^2$ fonksiyonumuz var. Tek boyutlu bu ortamda bir noktadan başlayıp
gradyanın (1. türev) işaret ettiği yönde ufak bir adım atmak bizi minimuma
daha yaklaştırır, ve bunu ardı ardına yaparak yerel bir minimuma
erisebiliriz. Örnek $f(x)$ dışbükey (convex) olduğu için bu bizi global
minimuma götürür [3]. Formül</p>
<p>$$
x_{i+1} = x_i + \alpha \nabla f(x_i)
$$</p>
<p>Başlangıç $x_0$ herhangi bir nokta, üstteki formülle adım ata ata
ilerliyoruz, adım boyutunu bizim tanımladığımız bir $\alpha$ sabitiyle
ayarlayabiliyoruz. </p>
<pre><code class="python">import autograd

def fun(x):
    return x**2

def grad_desc(x, fun, alpha=0.1, max_iter=100):
    xs = np.zeros(1 + max_iter)
    xs[0] = x
    grad = autograd.grad(fun)

    for step in range(max_iter):
        x = x - alpha * grad(x)
        xs[step + 1] = x

![](func_40_autograd_02.png)
    return xs

alpha = 0.1
x0 = 1.

x_opt = grad_desc(x0, fun, alpha = alpha, max_iter = 10)
y_opt = fun(x_opt)

x_true = np.linspace(-1.2, 1.2, 100)
y_true = fun(x_true)

plt.plot(x_true, y_true)
plt.plot(x_opt, y_opt, 'o-', c='red')

for i, (x, y) in enumerate(zip(x_opt, y_opt), 1):
      plt.text(x - 0.1, y + 0.1, i, fontsize=15)

plt.show()
</code></pre>

<p><img alt="" src="func_40_autograd_02.png" /></p>
<p>Türevi <code>autograd</code> ile aldık, bu örnekte sembolik türev kolaydı, elle
$f'(x)=2x$ diyebilirdik ama gösterim amaçlı direk yazılımla türevi aldık.</p>
<p>Kısıtlanmış Optimizasyon</p>
<p>Mühendislik problemlerinde kısıtlanmış optimizasyon çok ortaya
çıkar. Prototipik örnek bir düzlem üzerindeki orijine en yakın noktayı
bulmak. Mesela düzlem $2x - y + z = 3$ olsun, ve mesafeyi minimize etmek
istiyoruz, bunu $x^2+y^2+z^2$ ile hesaplayabiliriz. Yani optimizasyon
problemi düzlem denklemi ile sınırlanan mesafe formülünün minimal noktasını
bulmak [5]. </p>
<p>Problemi direk <code>scipy.optimize.minimize</code> ile çözelim. </p>
<pre><code class="python">from scipy.optimize import minimize

def objective(X): # hedef
    x, y, z = X
    return x**2 + y**2 + z**2

def cons(X): # kisitlama
    x, y, z = X
    return 2 * x - y + z - 3

x0 = [1, 1, 1]
sol = minimize(objective, x0, constraints={'type': 'eq', 'fun': cons})
print (sol)
</code></pre>

<pre><code>     fun: 1.5000000035790053
     jac: array([ 1.99997392, -1.00010441,  0.99994774])
 message: 'Optimization terminated successfully.'
    nfev: 22
     nit: 4
    njev: 4
  status: 0
 success: True
       x: array([ 0.99998696, -0.50005221,  0.49997386])
</code></pre>

<p>Fonksiyon <code>minimize</code> için kısıtlamalar <code>eq</code> ile sıfıra eşit olma
üzerinden tanımlanır. Eğer <code>ineq</code> kullanılırsa sıfırdan büyük olma
tanımlanıyor o zaman mesela $x&gt;0$ ve $x&lt;5$ kısıtlamalarını getirmek
istersek, </p>
<pre><code class="python">cons=({'type': 'ineq','fun': lambda xvec: 5.0-xvec[1]}, # y&lt;5
      {'type': 'ineq','fun': lambda xvec: xvec[1]}) # y&gt;0
sol = minimize(objective, x0, method = 'SLSQP', constraints=cons)
print (sol)
</code></pre>

<p>Not: <code>SLSQP</code> metotu gradyana ihtiyaç duymuyor. </p>
<pre><code>     fun: 1.1090612774580318e-16
     jac: array([7.79817877e-12, 1.49011612e-08, 7.79860898e-12])
 message: 'Optimization terminated successfully.'
    nfev: 20
     nit: 4
    njev: 4
  status: 0
 success: True
       x: array([-7.44668151e-09,  2.73897702e-24, -7.44668129e-09])
</code></pre>

<p>Bazen her şeyi kendimiz yaparak tüm adımların ne yaptığından emin olmak
isteyebiliriz. Mesela kısıtlama şartlarını kendimiz bir Lagrange çarpanı
$f(x) f(x) - \lambda g(x)$ ifadesi üzerinden tanımlayıp, türevi alıp sıfıra
eşitleyip, $f_x(x)=f_y(x)=f_z(x)=g(x)=0$ ile, elde edilen kısıtsız
optimizasyonu çözmeyi tercih edebiliriz. Türevin alınmasını direk
<code>autograd</code>'a yaptırırız.</p>
<pre><code class="python">import autograd.numpy as np
from autograd import grad

def F(L):
    x, y, z, _lambda = L
    return objective([x, y, z]) - _lambda * eq([x, y, z])

dfdL = grad(F, 0)

# Find L that returns all zeros in this function.
def obj(L):
    x, y, z, _lambda = L
    dFdx, dFdy, dFdz, dFdlam = dfdL(L)
    return [dFdx, dFdy, dFdz, eq([x, y, z])]

from scipy.optimize import fsolve
x, y, z, _lam = fsolve(obj, [0.0, 0.0, 0.0, 1.0])
print (x,y,z)
</code></pre>

<pre><code>1.0 -0.5 0.5
</code></pre>

<p>Aynı sonuç bulundu. Şimdi merak ediyoruz, bu sonuç gerçekten minimum mu?
Üstteki noktada Hessian'ın pozitif kesin olup olmadığını kontrol
edebiliriz. Hessian'ı da <code>autograd</code> hesaplar!</p>
<pre><code class="python">from autograd import hessian
h = hessian(objective, 0)
res = h(np.array([x, y, z]))
print (res)
</code></pre>

<pre><code>[[2. 0. 0.]
 [0. 2. 0.]
 [0. 0. 2.]]
</code></pre>

<p>Bu matris pozitif kesin, ama çıplak gözle bariz değilse, tüm özdeğerleri
pozitif olup olmadığına bakabiliriz, </p>
<pre><code class="python">print (np.linalg.eig(h(np.array([x, y, z])))[0])
</code></pre>

<pre><code>[2. 2. 2.]
</code></pre>

<p>Birden Fazla Gradyan Değişkeni</p>
<p>Diyelim ki elimizde </p>
<p>$$
g(w_1,w_2) = \tanh (w_1w_2)
$$</p>
<p>fonksiyonu var, bu üç boyutlu bir fonksiyon, ve optimizasyon amaçlı gradyan
gerekiyor, gradyanın iki değişken üzerinden alınması gerekli [7]. </p>
<pre><code class="python">import autograd
from autograd import numpy as anp

def g(w_1,w_2):
    return anp.tanh(w_1*w_2)

from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
x = np.linspace(-4,4,20)
y = np.linspace(-4,4,20)
xx,yy = np.meshgrid(x,y)
zz = g(xx,yy)
fig = plt.figure()
ax = fig.gca(projection='3d')
surf = ax.plot_surface(xx, yy, zz, cmap=cm.coolwarm)
plt.savefig('func_40_autograd_03.png')
</code></pre>

<p><img alt="" src="func_40_autograd_03.png" /></p>
<p>$g$'nin her iki kısmi türevini ve gradyanını, </p>
<p>$$
\nabla g(w_1,w_2) = \left[\begin{array}{r}
\frac{\partial }{\partial w_1} g(w_1,w_2) \\
\frac{\partial }{\partial w_2} g(w_1,w_2) 
\end{array}\right]
$$</p>
<p><code>autograd</code> ile hesaplamak için </p>
<pre><code class="python">dgdw1 = autograd.grad(g,0)
dgdw2 = autograd.grad(g,1)
</code></pre>

<p>Dikkat edersek, 0 ve 1 parametreleri geçildi, bunlar sırasıyla $w_1$ ve
$w_2$ değişkenlerine tekabül ediyorlar (<code>g</code> tanımındaki sıralarına
göre, 0. ve 1. parametreler). Şimdi mesela (1.0,2.0) noktasındaki gradyanı
hesaplayabiliriz,</p>
<pre><code class="python">gradg = [dgdw1(1.0,2.0), dgdw2(1.0,2.0)]
print (gradg)
</code></pre>

<pre><code>[0.14130164970632894, 0.07065082485316447]
</code></pre>

<p>Hessian</p>
<p>Mesela $f(x_1,x_2) = x_2^3 + x_2^3 + x_1^2x_2^2$ gibi bir fonksiyon var
diyelim. Belli bir noktadaki Hessian</p>
<p>$$
H = \left[\begin{array}{rr}
\frac{\partial f}{\partial x_1x_1} &amp; \frac{\partial f}{\partial x_1x_2} \\
\frac{\partial f}{\partial x_2x_1} &amp; \frac{\partial f}{\partial x_2x_2} 
\end{array}\right]
$$</p>
<p>hesaplatmak için <code>autograd.hessian</code> kullanırız,</p>
<pre><code class="python">import autograd 

def f(x):
    x1,x2=x[0],x[1]
    return x1**3 + x2**3 + (x1**2)*(x2**2)

print
xx = np.array([1.0,1.0])
h = autograd.hessian(f)
print (h(xx))
</code></pre>

<pre><code>[[8. 4.]
 [4. 8.]]
</code></pre>

<p>Esitsizlik Sınırlamaları </p>
<p>Optimizasyon problemimizde </p>
<p>$$
\min_x f(x), 
\quad 
\textrm{oyle ki}, 
\quad 
c_i(x) \ge 0, 
\quad i=1,2,..,m
$$</p>
<p>$c_i$ ile gösterilen eşitsizlik içeren (üstte büyüklük türünden)
kısıtlamalar olduğunu düşünelim. Bu problemi nasıl çözeriz?</p>
<p>Bir fikir, problemin eşitizliklerini bir gösterge (indicator)
fonksiyonu üzerinden, Lagrange yönteminde olduğu gibi, ana hedef
fonksiyonuna dahil etmek, ve elde edilen yeni hedefi kısıtlanmamış bir
problem gibi çözmek. Yani üstteki yerine, alttaki problemi çözmek,</p>
<p>$$
\min_x f(x) + \sum_{i=1}^{m} I(c_i(x))
$$</p>
<p>ki $I$ pozitif reel fonksiyonlar için göstergeç fonksiyonu,</p>
<p>$$
I(u) = 
\left\{ \begin{array}{ll}
0 &amp; u \le 0 \\
\infty &amp; u &gt; 0
\end{array} \right.
$$</p>
<p>Bu yaklaşımın nasıl işleyeceğini kabaca tahmin edebiliriz. $I$ fonksiyonu
0'dan büyük değerler için müthiş büyük değerler veriyor, bu sebeple
optimizasyon sırasında o değerlerden tabii ki kaçınılacak, ve arayış
istediğimiz noktalara doğru kayacak. Tabii $x_1 &gt; 3$ gibi bir şart varsa
onu $x_1 - 3 &gt; 0$ şartına değiştiriyoruz ki üstteki göstergeci
kullanabilelim. Bu yaklaşıma "bariyer metotu" ismi veriliyor çünkü $I$ ile
bir bariyer yaratılmış oluyor.</p>
<p>Fakat bir problem var, göstergeç fonksiyonunun türevini almak, ve pürüzsüz
rahat kullanılabilen bir yeni fonksiyon elde etmek kolay değil. Acaba $I$
yerine onu yaklaşık temsil edebilen bir başka sürekli fonksiyon kullanamaz
mıyız?</p>
<p>Log fonksiyonunu kullanabiliriz. Altta farklı $\mu$ değerleri için
$-\mu \log(-u)$ fonksiyonun değerlerini görüyoruz. Fonksiyon görüldüğü gibi
$I$'ya oldukca yakın.</p>
<pre><code class="python">def I(u): 
   if u&lt;0: return 0.
   else: return 10.0

u = np.linspace(-3,1,100)
Is = np.array([I(x) for x in u])

import pandas as pd
df = pd.DataFrame(index=u)

df['I'] = Is
df['$\mu$=0.5'] = -0.5*np.log(-u)
df['$\mu$=1.0'] = -1.0*np.log(-u)
df['$\mu$=2.0'] = -2.0*np.log(-u)

df.plot()
plt.savefig('func_40_autograd_04.png')
</code></pre>

<p><img alt="" src="func_40_autograd_04.png" /></p>
<p>O zaman eldeki tüm $c_i(x) \ge 0$ kısıtlamalarını</p>
<p>$$
- \sum_{i=1}^{m} \log c_i(x)
$$</p>
<p>ile hedef fonksiyonuna dahil edebiliriz, yeni birleşik fonksiyon,</p>
<p>$$
P(x;\mu) = f(x) - \mu \sum_{i=1}^{m} \log c_i(x) 
$$</p>
<p>olur. Böylece elde edilen yaklaşım log-bariyer yaklaşımı olacaktır. </p>
<p>Algoritma olarak optimizasyon şu şekilde gider;</p>
<p>1) Bir $x$ ve $\mu$ değerinden başla.</p>
<p>2) Newton metotu ile birkaç adım at (durma kriteri yaklaşıma göre değisebilir)</p>
<p>3) $\mu$'yu küçült</p>
<p>4) Ana durma kriterine bak, tamamsa dur. Yoksa başa dön</p>
<p>Bu yaklaşımın dışbükey (convex) problemler için global minimuma
gittiği ispatlanmıştır [8, sf. 504].</p>
<p>Örnek</p>
<p>$\min (x_1 + 0.5)^2 + (x_2 - 0.5)^2$ problemini çöz, $x_1 \in [0,1]$ ve $x_2 \in
[0,1]$ kriterine göre.</p>
<p>Üstteki fonksiyon için log-bariyer,</p>
<p>$$
P(x;\mu) = (x_1 + 0.5)^2 + (x_2-0.5)^2 -
\mu 
\big[
\log x_1 + \log (1-x_1) + \log x_2 + \log (1-x_2)
\big]
$$</p>
<p>Bu formülasyonu nasıl elde ettiğimiz bariz herhalde, $x_1 \ge 0$ ve
$x_1 \le 1$ kısıtlamaları var mesela, ikinci ifadeyi büyüktür
işaretine çevirmek için eksi ile çarptık, $-x_1 \ge 1$, ya da $1-x_1
\ge 0$ böylece $\log(1-x_1)$ oldu.</p>
<p>Artık Newton yöntemini kullanarak sanki elimizde bir kısıtlanması
olmayan fonksiyon varmış gibi kodlama yapabiliriz, $P$'yi minimize
edebiliriz. Newton yönü $d$ için gereken Hessian ve Jacobian
matrislerini otomatik türevle hesaplayacağız, belli bir noktadan
başlayacağız, ve her adımda $d = -H(x)^{-1} \nabla f(x)$ yönünde adım
atacağız.</p>
<pre><code class="python">from autograd import numpy as anp, grad, hessian, jacobian
import numpy.linalg as lin

x = np.array([0.8,0.2])
mu = 2.0
for i in range(10):
    def P(x):
        x1,x2=x[0],x[1]
        return (x1+0.5)**2 + (x2-0.5)**2 - mu * \
       (anp.log(x1) + anp.log(1-x1) + anp.log(x2)+anp.log(1-x2))

    h = hessian(P)
    j = jacobian(P)
    J = j(np.array(x))
    H = h(np.array(x))
    d = np.dot(-lin.inv(H), J)
    x = x + d
    print (i, x, np.round(mu,5))
    mu = mu*0.1
</code></pre>

<pre><code>0 [0.61678005 0.34693878] 2.0
1 [-0.00858974  0.486471  ] 0.2
2 [-0.02078755  0.49999853] 0.02
3 [-0.18014768  0.5       ] 0.002
4 [-0.49963245  0.5       ] 0.0002
5 [-0.50002667  0.5       ] 2e-05
6 [-0.50000267  0.5       ] 0.0
7 [-0.50000027  0.5       ] 0.0
8 [-0.50000003  0.5       ] 0.0
9 [-0.5  0.5] 0.0
</code></pre>

<p>Görüldüğü gibi 5. adımda optimal noktaya gelindi, o noktada $\mu$
oldukca küçük, ve bariyerle tanımladığımız yerlerden uzak duruldu,
optimal nokta $x_1=-0.5,x_2=0.5$ bulundu.</p>
<p>[devam edecek]</p>
<p>Kaynaklar </p>
<p>[1] Bayramlı, Ders Notları, <em>Otomatik Türev Almak (Automatic Differentiation -AD-)</em></p>
<p>[2] Schrimpf, <a href="http://faculty.arts.ubc.ca/pschrimpf/526/526.html">http://faculty.arts.ubc.ca/pschrimpf/526/526.html</a></p>
<p>[3] Stoyanov, <a href="https://nikstoyanov.me/post/2019-04-14-numerical-optimizations">https://nikstoyanov.me/post/2019-04-14-numerical-optimizations</a></p>
<p>[5] Kitchin, <a href="http://kitchingroup.cheme.cmu.edu/blog/2018/11/03/Constrained-optimization-with-Lagrange-multipliers-and-autograd/">http://kitchingroup.cheme.cmu.edu/blog/2018/11/03/Constrained-optimization-with-Lagrange-multipliers-and-autograd/</a></p>
<p>[6] Bayramli, Cok Boyutlu Calculus, <em>Vektör Calculus, Kurallar, Matris Türevleri</em></p>
<p>[7] Watt, <em>Automatic Differentiation</em>, 
    \url{https://jermwatt.github.io/machine_learning_refined/notes/3_First_order_methods/3_5_Automatic.html}</p>
<p>[8] Nocedal, <em>Numerical Optimization</em></p>