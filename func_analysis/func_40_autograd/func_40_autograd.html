<h1>Autograd ile Optimizasyon</h1>
<!DOCTYPE html>
<html>
  <head>
    <title>Autograd ile Optimizasyon
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
</script>
</head>

<p>Otomatik türevin nasıl işlediğini [1] yazısında gördük. Programlama dilinde
yazılmış, içinde <code>if</code>, <code>case</code>, hatta döngüler bile içerebilen
herhangi bir kod parçasının türevini alabilmemizi sağlayan otomatik türev
almak pek çok alanda işimize yarar. Optimizasyon alanı bunların başında
geliyor. Düşünürsek, eğer sembolik olarak türev alması çok çetrefil bir
durum varsa, tasaya gerek yok; bir fonksiyonu kodlayabildiğimiz anda onun
türevini de alabiliriz demektir.</p>
<p>Önce bazı genel optimizasyon konularını işleyelim. </p>
<p>Sınırlanmamış optimizasyonda (unconstrained optimization) $f(x)$
fonksiyonunu minimum değerde tutacak $x$ değerini bulmaya uğraşıyoruz, ki
$x$ tek boyutlu skalar, ya da çok boyutlu $x \in \mathbb{R}^n$
olabilir. Yani yapmaya uğraştığımız</p>
<p>$$
\min_x f(x)
$$</p>
<p>işlemi. Peki minimumu nasıl tanımlarız? Bir nokta $x^*$ global minimize
edicidir eğer tüm $x$'ler için $f(x^*) \le f(x)$ ise, ki
$x \in \mathbb{R}^n$, en azından $x$ modelleyeni ilgilendiren tüm küme
öğeleri için.</p>
<p>Fakat çoğu zaman bir global $f$'i kullanmak mümkün olmayabilir, fonksiyon
çok çetrefil, çok boyutlu, bilinmez durumdadır, ve elimizde sadece yerel
bilgi vardır. Bu durumda üstteki tanımı "bir $N$ bölgesi içinde" olacak
şekilde değiştiririz ki bölge, $x^*$ etrafındaki, yakınındaki bölgedir.</p>
<p>Üstteki tanımı okuyunca  $x^*$'in yerel minimum olup olmadığını anlamanın
tek yolunun yakındaki diğer tüm noktalara teker teker bakmak olduğu anlamı
çıkabilir, fakat eğer $f$ pürüzsüz bir fonksiyon ise yerel minimumu
doğrulamanın çok daha hızlı bir yöntemi vardır. Hatta ve hatta eğer
fonksiyon $f$ iki kez türevi alınabilir haldeyse $x^*$'in yerel minimum
olduğunu ispatlamak daha kolaylaşır, $\nabla f(x^*)$ ve Hessian $\nabla^2
f(x^*)$'e bakarak bunu yapabiliriz.</p>
<p>Pürüzsüz fonksiyonların minimize edicilerini incelemekte kullanacağımız
araç Taylor'un teorisi olacak. </p>
<p>Taylor'un Teorisi</p>
<p>$f: \mathbb{R}^n \to \mathbb{R}$'nin sürekli türevi alınabilir olduğunu farz
edelim ve $p \in \mathbb{R}^n$ olacak şekilde,</p>
<p>$$
f(x + p) = f(x) + \nabla f(x + tp)^T p
$$</p>
<p>ki $t \in (0,1)$. Ayrıca eğer $f$ iki kez türevi alınabilir halde ise,</p>
<p>$$
\nabla f(x+p) = \nabla f(x) + \int_{0}^{1}\nabla^2 f(x+tp) p \mathrm{d} t
$$</p>
<p>ve </p>
<p>$$
f(x+p) = f(x) + \nabla f(x)^T p + \frac{1}{2} p^T \nabla^2 f(x+tp) p
$$</p>
<p>[devam edecek]</p>
<p>Kaynaklar </p>
<p>[1] Bayramlı, Ders Notları, <em>Otomatik Türev Almak (Automatic Differentiation -AD-)</em></p>
<p>[3] <a href="https://nikstoyanov.me/post/2019-04-14-numerical-optimizations">https://nikstoyanov.me/post/2019-04-14-numerical-optimizations</a></p>
<p>[4] <a href="https://rlhick.people.wm.edu/posts/mle-autograd.html">https://rlhick.people.wm.edu/posts/mle-autograd.html</a></p>
<p>[5] <a href="http://kitchingroup.cheme.cmu.edu/blog/2018/11/03/Constrained-optimization-with-Lagrange-multipliers-and-autograd/">http://kitchingroup.cheme.cmu.edu/blog/2018/11/03/Constrained-optimization-with-Lagrange-multipliers-and-autograd/</a></p>