\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Tam Varyasyon ile Gürültüyü Yoketmek (Total Variation Denoising)

Bir sinyalden, görüntüden gürültü çýkartmak için optimizasyon
kullanýlabilir. Orijinal sinyal $x$'in $y = B x + n$ ile bir $n$ gürültüsü
eklenerek bozulduðu (corrupted) farzedilebilir ($B$ bir deðiþim matrisidir,
tutarlý, bilinen deðiþimleri temsil eder) biz eldeki $y$ ile $x$'i
kestirmeye uðraþýrýz.  Fakat literatürde iyi bilindiði üzere $x$'i $y$'den
tahmin etmeye uðraþmak kötü konumlanmýþ (ill-posed) bir sorudur. Çözüm
olabilecek pek çok $x$ bulunabilir, bu sebeple arama alanýný bir þekilde
daraltmak gerekir, ve bunun için bir tür düzenlileþtirme / regülarizasyon
(regularization) kullanýlmasý þarttýr [3].

Bir sayýsal resimden gürültü çýkartma alanýnda iyi bilinen bir yöntem
problemi çift hedefli bir halde konumlandýrmak [4],

$$
|| x-x_{cor}||_2, \qquad \phi_{tv} (x) = \sum_{i=1}^{n-1} | x_{i+1} - x_i | 
\mlabel{1}
$$

Burada $x_{cor} \in \mathbb{R}^n$ bize verilen bozulmuþ sinyal,
$x \in \mathbb{R}^n$ ise bulmak istediðimiz, gürültüsü çýkartýlmýþ sinyal,
$\phi_{tv}$ ise tam varyasyon fonksiyonu. Üstteki iki hedefi minimize etmek
istiyoruz, böylece ayný anda hem sinyalin kendi içindeki varyasyonu azaltan
hem de bozulmuþ sinyale mümkün olduðunca yakýn duran bir gerçek $x$ elde
edebilelim.

Her iki hedef fonksiyonunu birleþtirip tek bir fonksiyon haline getirip onu
kýsýtlanmamýþ (unconstrained) bir optimizasyon problemi olarak çözebiliriz,

$$
\psi = || x-x_{cor}||_2^2 + \mu \phi_{tv} 
$$

ki $\mu$ bizim seçeceðimiz bir parametre olabilir. Çözüm için mesela Newton
metodunu kullanabiliriz, fakat tek bir problem var, Newton ve ona benzer
diðer optimizasyon metotlarý için türev almak gerekli, fakat
$\phi_{tv}$'deki L1-norm'unun (tek boyutta mutlak deðer fonksiyonu)
$x=0$'da türevi yoktur (birinci terimdeki Oklit normunun karesi alýndýðý
için onun iki kere türevi alýnabilir). Bu durumda $\phi_{tv}$'yi yaklaþýk
olarak temsil edebilirsek, onun da türevi alýnýr hale gelmesi
saðlayabiliriz. Bu yeni fonksiyona $\phi_{atv}$ diyelim,

$$
\phi_{atv} = \sum _{i=1}^{n-1} 
\left( \sqrt{ \epsilon^2 + (x_{i+1})-x_i  } - \epsilon \right)
$$

ki $\epsilon > 0$ yaklaþýklamanýn seviyesini ayarlýyor. Bu fonksiyonun iyi
bir yaklaþýklama olduðunu görmek zor deðil, toplam içindeki kýsmý deneyerek
görelim,

\begin{minted}[fontsize=\footnotesize]{python}
import numpy as np

eps = 1e-6
mu = 50.0

def norm_tv(x):
   return np.sum(np.abs(np.diff(x)))
   
def norm_atv(x):
   return np.sum(np.sqrt(eps + np.power(np.diff(x),2)) - eps)
   
xcor = np.random.randn(1000)

print (norm_tv(xcor))
print (norm_atv(xcor))
\end{minted}

\begin{verbatim}
1103.2561038302395
1103.2571969067808
\end{verbatim}

Üstteki fonksiyonun iki kez türevi alýnabilir. Þimdi analitik þekilde devam
etmeden önce pür sayýsal açýdan bir çözüme bakalým. Üstteki fonksiyonlarý
direk kodlayarak ve sayýsal türev üzerinden iþleyebilen bir kütüphane
çaðrýsýyla hedefi minimize edelim, eldeki sinyal,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
df = pd.read_csv('xcor.csv',header=None)
xcor = np.reshape(np.array(df[0]), (5000,1))
plt.plot(range(len(xcor)), xcor)
plt.savefig('func_60_tvd_01.png')
\end{minted}

\includegraphics[width=25em]{func_60_tvd_01.png}

Kütüphane çaðrýsý ile

\begin{minted}[fontsize=\footnotesize]{python}
x0 = np.zeros(len(xcor))

from scipy.optimize import minimize, Bounds, SR1, BFGS

def phi(x):
   return np.sum(np.power(x-xcor, 2)) + mu*norm_atv(x)

opts = {'maxiter': 400, 'verbose': 2}

res = minimize (fun=phi,
                x0=x0,
                options=opts,
                jac='2-point',
                hess=BFGS(),
                method='trust-constr'
                )

plt.plot(range(5000), res.x)
plt.savefig('func_60_tvd_02.png')
\end{minted}

\includegraphics[width=25em]{func_60_tvd_02.png}

Sonuç fena olmadý. Fakat üstteki yaklaþýmýn hesabý uzun sürecektir, eðer
eldeki problem hakkýnda bazý ek þeyler biliyorsak, bu bilgileri dahil
ederek elde edilen çözüm daha hýzlý olabilir. Mesela analitik olarak
türevler Jacobian ve Hessian bulunabilir, Newton adýmý elle kodlanabilir,
ayrýca problemdeki matrislerde muhtemel bir seyreklikten (sparsity)
faydalanýlabilir.

Hedef fonksiyonu, $\psi(x)$ diyelim, için birinci ve ikinci türev,

$$
\nabla \psi(x) = 2 (x-x_{cor}) + \mu \nabla \phi_{atv}(x), \qquad
\nabla^2 \psi(x) = 2 I + \mu \nabla^2 \phi_{atv} (x)
$$

Zincirleme Kuralý uygulandý tabii, ve þimdi $\phi_{atv}$ üzerindeki
türevleri bulmak gerekiyor. Sorun deðil, daha önceki yaklaþýklamayý bunun
için yapmýþtýk zaten. Yaklaþýk fonksiyonu genel olarak belirtirsek, 

$$
f(u) = \sqrt{\epsilon^2 + u^2} - \epsilon
$$

Bu fonksiyonun 1. ve 2. türevi

$$
f'(u) = u(\epsilon^2 + u^{-1/2} ), \qquad
f''(u) = \epsilon^2 (\epsilon^2 + u^2)^{-3/2}
$$

Þimdi bir $F$ tanýmlayalým,

$$
F(u_1,..., u_{n-1}) = \sum_{i=1}^{n-1} f(u_i)
$$

Yani $F(u)$ $u$'nun bileþenlerinin yaklaþýk L1 norm'unun toplamýdýr. Nihai
amacýmýz bu tanýmdan bir $\phi_{atv}$ ifadesine ulaþmak. $F$'in gradyaný ve
Hessian'ý

$$
\nabla F(u) = \left[\begin{array}{ccc} f'(u_1) & \dots & f'(u_{n-1}) \end{array}\right]
$$

$$
\nabla^2 F(u) = 
\diag 
\left[\begin{array}{ccc} f''(u_1) & \dots & f''(u_{n-1}) \end{array}\right] 
$$

Eðer bir ileri farklýlýk matrisi $D$ tanýmlarsak, 

$$
D = \left[\begin{array}{ccccc}
-1  & 1 & & &    \\
 & -1 & 1 & &   \\
 &  & \ddots  & \ddots &  \\
 &  &  &  -1 & 1
\end{array}\right]
$$

O zaman $\phi_{atv}(x) = F(Dx)$ diyebiliriz. Bir $x$ vektörünü
üstteki matris ile soldan çarpýnca öðeleri 
$\left[\begin{array}{ccc} x_2-x_1 & x_3-x_2 & \dots \end{array}\right]$ 
þeklinde giden bir yeni vektör elde edeceðimizi doðrulamak zor deðil. Yine
Zincirleme Kuralýný uygularsak,

$$
\nabla \phi_{atv}(x) = D^T \nabla F(Dx), \qquad
\nabla^2 \phi_{atv}(x) = D^T \nabla^2 F(Dx) D
$$

Hepsini bir araya koyarsak 

$$
\nabla \psi(x) = 2(x-x_{cor}) + \mu D^T \nabla F(Dx)
$$

$$
\nabla^2 \psi(x) = 2 I  + \mu D^T \nabla^2 F(Dx) D
$$

Kodlamayý alttaki gibi yapabiliriz,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
import scipy.sparse as sps
import scipy.sparse.linalg as slin

MU = 50.0
EPSILON = 0.001

ALPHA = 0.01;
BETA = 0.5;
MAXITERS = 100;
NTTOL = 1e-10;

n = len(xcor)
data = np.array([-1*np.ones(n), np.ones(n)])
diags = np.array([0, 1])
D = sps.spdiags(data, diags, n-1, n)

x = np.zeros((len(xcor),1))

for iter in range(MAXITERS):
   d = D.dot(x)
   val1 = np.dot((x-xcor).T,(x-xcor))
   val2 = np.sqrt(EPSILON**2 + np.power(d,2))
   val3 = EPSILON*np.ones((n-1,1))
   val = np.float(val1 + MU*np.sum(val2 - val3))
   grad1 = 2*(x-xcor)
   grad2 = MU*D.T.dot(d / np.sqrt(EPSILON**2 + d**2))
   grad = grad1 + grad2
   hess1 = 2*sps.eye(n)
   hess2 = EPSILON**2*(EPSILON**2+d**2)**(-3/2)
   hess2 = hess2.reshape((n-1))
   hess3 = sps.spdiags(hess2, 0, n-1, n-1)

   hess = hess1 + MU*hess3.dot(D).T.dot(D)
   v = slin.spsolve(-hess, grad)
   v = np.reshape(v, (n,1))
   lambdasqr = np.float(np.dot(-grad.T,v))
   if lambdasqr/2 < NTTOL: break
   t = 1;
   while True:
      tmp1 = np.float(np.dot((x+t*v-xcor).T,(x+t*v-xcor)))
      tmp2 = MU*np.sum(np.sqrt(EPSILON**2+(D*(x+t*v))**2)-EPSILON*np.ones((n-1,1)))
      tmp3 = val - ALPHA*t*lambdasqr
      if tmp1 + tmp2 < tmp3: break
      t = BETA*t

   x = x+t*v

plt.plot(range(n),xcor)
plt.plot(range(n),x,'r')
plt.savefig('func_60_tvd_03.png')
\end{minted}

\includegraphics[width=25em]{func_60_tvd_03.png}

Çok daha iyi bir gürültüsüz sonuç elde ettik, üstteki bu iþlem çok daha
hýzlý. 

Kaynaklar

[1] Mordvintsev, {\em ROF and TV-L1 denoising with Primal-Dual algorithm},
    \url{https://github.com/znah/notebooks/blob/master/TV_denoise.ipynb}

[2] Chambolle, {\em An introduction to continuous optimization for imaging},
    \url{https://hal.archives-ouvertes.fr/hal-01346507/document}

[3] Afonso, {\em Fast Image Recovery Using Variable Splitting and Constrained Optimization},
    \url{http://www.lx.it.pt/~mtf/Afonso_BioucasDias_Figueiredo_twocolumn_v7.pdf}

[4] Boyd, 
    {\em Additional Exercises for Convex Optimization}
    \url{https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook_extra_exercises.pdf}






\end{document}





