\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Tam Varyasyon ile Gürültü Çýkartmak (Total Variation Denoising)

Bir sinyalden, görüntüden gürültü çýkartmak için optimizasyon
kullanýlabilir. Orijinal sinyal $x$'in $y = B x + n$ ile bir $n$ gürültüsü
eklenerek bozulduðu (corrupted) farzedilebilir ($B$ bir deðiþim matrisidir,
tutarlý, bilinen deðiþimleri temsil eder) biz eldeki $y$ ile $x$'i
kestirmeye uðraþýrýz.  Fakat literatürde iyi bilindiði üzere $x$'i $y$'den
tahmin etmeye uðraþmak kötü konumlanmýþ (ill-posed) bir sorudur. Çözüm
olabilecek pek çok $x$ bulunabilir, bu sebeple arama alanýný bir þekilde
daraltmak gerekir, ve bunun için bir tür düzenlileþtirme / regülarizasyon
(regularization) kullanýlmasý þarttýr [3].

Bir sayisal resimden gürültü çýkartma alanýnda iyi bilinen bir yöntem,
problemi çift hedefli bir halde konumlandýrmak [4],

$$
|| x-x_{cor}||_2, \qquad \phi_{tv} (x) = \sum_{i=1}^{n-1} | x_{i+1} - x_i | 
\mlabel{1}
$$

Burada $x_{cor} \in \mathbb{R}^n$ bize verilen bozulmuþ sinyal,
$x \in \mathbb{R}^n$ ise bizim bulmak istediðimiz, gürültüsü çýkartýlmýþ
sinyal, $\phi_{tv}$ ise tam varyasyon fonksiyonu. Üstteki iki hedefi
minimize etmek istiyoruz, böylece ayný anda hem sinyalin kendi içindeki
varyasyonu azaltan hem de bozulmuþ sinyale mümkün olduðunca yakýn duran bir
gerçek $x$ elde edebilelim.

Her iki hedef fonksiyonunu birleþtirip tek bir fonksiyon haline getirip onu
kýsýtlanmamýþ (unconstrained) bir optimizasyon problemi olarak çözebiliriz,

$$
\psi = || x-x_{cor}||_2 + \mu \phi_{tv} 
$$

ki $\mu$ bizim seçeceðimiz bir parametre olabilir. Çözüm için mesela Newton
metodunu kullanabiliriz, fakat tek bir problem var, Newton ve ona benzer
diðer optimizasyon metotlarý için türev almak gerekli, fakat
$\phi_{tv}$'deki L1-norm'unun (tek boyutta mutlak deðer fonksiyonu)
$x=0$'da türevi yoktur (birinci terimdeki Oklit normunun karesi alýndýðý
için onun iki kere türevi alýnabilir). Bu durumda $\phi_{tv}$'yi yaklaþýk
olarak temsil edebilirsek, onun da türevi alýnýr hale gelmesi
saðlayabiliriz. Bu yeni fonksiyona $\phi_{atv}$ diyelim,

$$
\phi_{atv} = \sum _{i=1}^{n-1} 
\left( \sqrt{ \epsilon^2 + (x_{i+1})-x_i  } - \epsilon \right)
$$

ki $\epsilon > 0$ yaklaþýklamanýn seviyesini ayarlýyor. Bu fonksiyonun iyi
bir yaklaþýklama olduðunu görmek zor deðil, tabii deneyerek görelim,

\begin{minted}[fontsize=\footnotesize]{python}
import numpy as np

eps = 1e-6
mu = 50.0

def phi_tv(x):
   return np.sum(np.abs(np.diff(x)))
   
def phi_atv(x):
   return np.sum(np.sqrt(eps + np.power(np.diff(x),2)) - eps)
   
def f(u):
   return np.sum(np.power(u-xcor, 2)) + mu*phi_atv(u)

xcor = np.random.randn(1000)

print (phi_tv(xcor))
print (phi_atv(xcor))
\end{minted}

\begin{verbatim}
1037.4372101629049
1037.438996069622
\end{verbatim}

Üstteki fonksiyonun iki kez türevi alýnabilir. Þimdi analitik þekilde devam
etmeden önce pür sayýsal açýdan bir çözüme bakalým. Üstteki fonksiyonlarý
direk kodlayarak ve sayýsal türev üzerinden iþleyebilen bir kütüphane
çaðrýsýyla hedefi minimize edelim, eldeki sinyal,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
df = pd.read_csv('xcor.csv',header=None)
xcor = np.reshape(np.array(df[0]), (5000,1))
plt.plot(range(len(xcor)), xcor)
plt.savefig('func_60_tvd_01.png')
\end{minted}

\includegraphics[width=25em]{func_60_tvd_01.png}

Kütüphane çaðrýsý ile

\begin{minted}[fontsize=\footnotesize]{python}
u0 = np.zeros(len(xcor))
print (f(u0))

from scipy.optimize import minimize, Bounds, SR1, BFGS

opts = {'maxiter': 400, 'verbose': 2}

res = minimize (fun=f,
                x0=u0,
                options=opts,
                jac='2-point',
                hess=BFGS(),
                method='trust-constr'
                )

plt.plot(range(5000), res.x)
plt.savefig('func_60_tvd_02.png')
\end{minted}

\includegraphics[width=25em]{func_60_tvd_02.png}

Sonuç fena olmadý. Fakat üstteki yaklaþýmýn hesabý uzun sürecektir, eðer
eldeki problem hakkýnda bazý ek þeyler biliyorsak, bu bilgileri dahil
ederek elde edilen çözüm daha hýzlý olabilir. Mesela analitik olarak
türevler Jacobian ve Hessian bulunabilir, Newton adýmý elle kodlanabilir,
ayrýca problemdeki matrislerde muhtemel bir seyreklikten (sparsity)
faydalanýlabilir.

Hedef fonksiyonu $\psi(x)$ diyelim, icin birinci ve ikinci turev, 

$$
\nabla \psi(x) = 2 (x-x_{cor}) + \mu \nabla \phi_{atv}(x), \qquad
\nabla^2 \psi(x) = 2 I + \mu \nabla^2 \phi_{atv} (x)
$$

Zincirleme Kuralý uygulandý tabii, ve þimdi $\phi_{atv}$ üzerindeki
türevleri bulmak gerekiyor. Sorun deðil, daha önceki yaklaþýklamayý bunun
için yapmýþtýk zaten. Yaklaþýk fonksiyonu genel olarak belirtirsek, 

$$
f(u) = \sqrt{\epsilon^2 + u^2} - \epsilon
$$

Bu fonksiyonun 1. ve 2. türevi

$$
f'(u) = u(\epsilon^2 + u^{-1/2} ), \qquad
f''(u) = \epsilon^2 (\epsilon^2 + u^2)^{-3/2}
$$

















[devam edecek]


\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
import scipy.sparse as sps
import scipy.sparse.linalg as slin

MU = 50.0
EPSILON = 0.001

ALPHA = 0.01;
BETA = 0.5;
MAXITERS = 100;
NTTOL = 1e-10;

n = len(xcor)
data = np.array([-1*np.ones(n), np.ones(n)])
diags = np.array([0, 1])
D = sps.spdiags(data, diags, n-1, n)

x = np.zeros((len(xcor),1))

for iter in range(MAXITERS):
   d = D.dot(x)
   tmp1 = np.dot((x-xcor).T,(x-xcor))
   tmp2a = np.sqrt(EPSILON**2 + np.power(d,2))
   tmp2b = EPSILON*np.ones((n-1,1))
   val = np.float(tmp1 + MU*np.sum(tmp2a - tmp2b))
   tmp1 = 2*(x-xcor)
   tmp2 = MU*D.T.dot(d / np.sqrt(EPSILON**2 + d**2))
   grad = tmp1 + tmp2
   tmp1 = 2*sps.eye(n)
   tmp2 = EPSILON**2*(EPSILON**2+d**2)**(-3/2)
   tmp2 = tmp2.reshape((n-1))
   tmp3 = sps.spdiags(tmp2, 0, n-1, n-1)

   hess = tmp1 + MU*tmp3.dot(D).T.dot(D)
   v = slin.spsolve(-hess, grad)
   v = np.reshape(v, (n,1))
   lambdasqr = np.float(np.dot(-grad.T,v))
   if lambdasqr/2 < NTTOL: break
   t = 1;
   while True:
      tmp1 = np.float(np.dot((x+t*v-xcor).T,(x+t*v-xcor)))
      tmp2 = MU*np.sum(np.sqrt(EPSILON**2+(D*(x+t*v))**2)-EPSILON*np.ones((n-1,1)))
      tmp3 = val - ALPHA*t*lambdasqr
      if tmp1 + tmp2 < tmp3: break
      t = BETA*t

   x = x+t*v

plt.plot(range(n),xcor)
plt.plot(range(n),x,'r')
plt.savefig('func_60_tvd_03.png')
\end{minted}

\includegraphics[width=25em]{func_60_tvd_03.png}

Kaynaklar

[1] {\em ROF and TV-L1 denoising with Primal-Dual algorithm}, 
    \url{https://github.com/znah/notebooks/blob/master/TV_denoise.ipynb}

[2] {\em An introduction to continuous optimization for imaging}, 
    \url{https://hal.archives-ouvertes.fr/hal-01346507/document}

[3] Afonso, {\em Fast Image Recovery Using Variable Splitting and Constrained Optimization},
    \url{http://www.lx.it.pt/~mtf/Afonso_BioucasDias_Figueiredo_twocolumn_v7.pdf}

[4] Boyd, {\em Additional Exercises for Convex Optimization}
    \url{https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook_extra_exercises.pdf}

\end{document}



