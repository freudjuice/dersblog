<h1>Tam Varyasyon ile Gürültü Çıkartmak (Total Variation Denoising)</h1>
<!DOCTYPE html>
<html>
  <head>
    <title>Tam Varyasyon ile Gürültü Çıkartmak (Total Variation Denoising)
</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [["$","$"]]}
      });
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    </script>
<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full">
</script>
</head>

<p>Bir sinyalden, görüntüden gürültü çıkartmak için optimizasyon
kullanılabilir. Orijinal sinyal $x$'in $y = B x + n$ ile bir $n$ gürültüsü
eklenerek bozulduğu (corrupted) farzedilebilir ($B$ bir değişim matrisidir,
tutarlı, bilinen değişimleri temsil eder) biz eldeki $y$ ile $x$'i
kestirmeye uğraşırız.  Fakat literatürde iyi bilindiği üzere $x$'i $y$'den
tahmin etmeye uğraşmak kötü konumlanmış (ill-posed) bir sorudur. Çözüm
olabilecek pek çok $x$ bulunabilir, bu sebeple arama alanını bir şekilde
daraltmak gerekir, ve bunun için bir tür düzenlileştirme / regülarizasyon
(regularization) kullanılması şarttır [3].</p>
<p>Bir sayisal resimden gürültü çıkartma alanında iyi bilinen bir yöntem,
problemi çift hedefli bir halde konumlandırmak [4],</p>
<p>$$
|| x-x_{cor}||_2, \qquad \phi_{tv} (x) = \sum_{i=1}^{n-1} | x_{i+1} - x_i | 
\qquad (1)
$$</p>
<p>Burada $x_{cor} \in \mathbb{R}^n$ bize verilen bozulmuş sinyal,
$x \in \mathbb{R}^n$ ise bizim bulmak istediğimiz, gürültüsü çıkartılmış
sinyal, $\phi_{tv}$ ise tam varyasyon fonksiyonu. Üstteki iki hedefi
minimize etmek istiyoruz, böylece aynı anda hem sinyalin kendi içindeki
varyasyonu azaltan hem de bozulmuş sinyale mümkün olduğunca yakın duran bir
gerçek $x$ elde edebilelim.</p>
<p>Her iki hedef fonksiyonunu birleştirip tek bir fonksiyon haline getirip onu
kısıtlanmamış (unconstrained) bir optimizasyon problemi olarak çözebiliriz,</p>
<p>$$
\psi = || x-x_{cor}||_2 + \mu \phi_{tv} 
$$</p>
<p>ki $\mu$ bizim seçeceğimiz bir parametre olabilir. Çözüm için mesela Newton
metodunu kullanabiliriz, fakat tek bir problem var, Newton ve ona benzer
diğer optimizasyon metotları için türev almak gerekli, fakat
$\phi_{tv}$'deki L1-norm'unun (tek boyutta mutlak değer fonksiyonu)
$x=0$'da türevi yoktur (birinci terimdeki Oklit normunun karesi alındığı
için onun iki kere türevi alınabilir). Bu durumda $\phi_{tv}$'yi yaklaşık
olarak temsil edebilirsek, onun da türevi alınır hale gelmesi
sağlayabiliriz. Bu yeni fonksiyona $\phi_{atv}$ diyelim,</p>
<p>$$
\phi_{atv} = \sum _{i=1}^{n-1} 
\left( \sqrt{ \epsilon^2 + (x_{i+1})-x_i  } - \epsilon \right)
$$</p>
<p>ki $\epsilon &gt; 0$ yaklaşıklamanın seviyesini ayarlıyor. Bu fonksiyonun iyi
bir yaklaşıklama olduğunu görmek zor değil, tabii deneyerek görelim,</p>
<pre><code class="python">import numpy as np

eps = 1e-6
mu = 50.0

def phi_tv(x):
   return np.sum(np.abs(np.diff(x)))

def phi_atv(x):
   return np.sum(np.sqrt(eps + np.power(np.diff(x),2)) - eps)

def f(u):
   return np.sum(np.power(u-xcor, 2)) + mu*phi_atv(u)

xcor = np.random.randn(1000)

print (phi_tv(xcor))
print (phi_atv(xcor))
</code></pre>

<pre><code>1037.4372101629049
1037.438996069622
</code></pre>

<p>Üstteki fonksiyonun iki kez türevi alınabilir. Şimdi analitik şekilde devam
etmeden önce pür sayısal açıdan bir çözüme bakalım. Üstteki fonksiyonları
direk kodlayarak ve sayısal türev üzerinden işleyebilen bir kütüphane
çağrısıyla hedefi minimize edelim, eldeki sinyal,</p>
<pre><code class="python">import pandas as pd
df = pd.read_csv('xcor.csv',header=None)
xcor = np.reshape(np.array(df[0]), (5000,1))
plt.plot(range(len(xcor)), xcor)
plt.savefig('func_60_tvd_01.png')
</code></pre>

<p><img alt="" src="func_60_tvd_01.png" /></p>
<p>Kütüphane çağrısı ile</p>
<pre><code class="python">u0 = np.zeros(len(xcor))
print (f(u0))

from scipy.optimize import minimize, Bounds, SR1, BFGS

opts = {'maxiter': 400, 'verbose': 2}

res = minimize (fun=f,
                x0=u0,
                options=opts,
                jac='2-point',
                hess=BFGS(),
                method='trust-constr'
                )

plt.plot(range(5000), res.x)
plt.savefig('func_60_tvd_02.png')
</code></pre>

<p><img alt="" src="func_60_tvd_02.png" /></p>
<p>Sonuç fena olmadı. Fakat üstteki yaklaşımın hesabı uzun sürecektir, eğer
eldeki problem hakkında bazı ek şeyler biliyorsak, bu bilgileri dahil
ederek elde edilen çözüm daha hızlı olabilir. Mesela analitik olarak
türevler Jacobian ve Hessian bulunabilir, Newton adımı elle kodlanabilir,
ayrıca problemdeki matrislerde muhtemel bir seyreklikten (sparsity)
faydalanılabilir.</p>
<p>Hedef fonksiyonu $\psi(x)$ diyelim, icin birinci ve ikinci turev, </p>
<p>$$
\nabla \psi(x) = 2 (x-x_{cor}) + \mu \nabla \phi_{atv}(x), \qquad
\nabla^2 \psi(x) = 2 I + \mu \nabla^2 \phi_{atv} (x)
$$</p>
<p>Zincirleme Kuralı uygulandı tabii, ve şimdi $\phi_{atv}$ üzerindeki
türevleri bulmak gerekiyor. Sorun değil, daha önceki yaklaşıklamayı bunun
için yapmıştık zaten. Yaklaşık fonksiyonu genel olarak belirtirsek, </p>
<p>$$
f(u) = \sqrt{\epsilon^2 + u^2} - \epsilon
$$</p>
<p>Bu fonksiyonun 1. ve 2. türevi</p>
<p>$$
f'(u) = u(\epsilon^2 + u^{-1/2} ), \qquad
f"(u) = \epsilon^2 (\epsilon^2 + u^2)^{-3/2}
$$</p>
<p>Simdi bir $F$ tanimlayalim,</p>
<p>$$
F(u_1,..., u_{n-1}) = \sum_{i=1}^{n-1} f(u_i)
$$</p>
<p>Yani $F(u)$ $u$'nun bilesenlerinin yaklasik L1 norm'unun toplamidir. Nihai
amacimiz bu tanimdan bir $\phi_{atv}$ ifadesine ulasmak. $F$'in gradyani ve
Hessian'i</p>
<p>$$
\nabla F(u) = \left[\begin{array}{ccc} f'(u_1) &amp; \dots &amp; f'(u_{n-1}) \end{array}\right]
$$</p>
<p>$$
\nabla^2 F(u) = 
\mathrm{diag} 
\left[\begin{array}{ccc} f"(u_1) &amp; \dots &amp; f"(u_{n-1}) \end{array}\right] 
$$</p>
<p>Eğer bir ileri farklılık matrisı $D$ tanımlarsak, </p>
<p>$$
D = \left[\begin{array}{ccccc}
-1  &amp; 1 &amp; &amp; &amp;    \\
 &amp; -1 &amp; 1 &amp; &amp;   \\
 &amp;  &amp; \ddots  &amp; \ddots &amp;  \\
 &amp;  &amp;  &amp;  -1 &amp; 1
\end{array}\right]
$$</p>
<p>O zaman $\phi_{atv}(x) = F(Dx)$ diyebiliriz. Bir $x$ vektörünü
üstteki matris ile soldan çarpınca öğeleri 
$\left[\begin{array}{ccc} x_2-x_1 &amp; x_3-x_2 &amp; \dots \end{array}\right]$ 
şeklinde giden bir yeni vektör elde edeceğimizi doğrulamak zor değil. Yine
Zincirleme Kuralını uygularsak,</p>
<p>$$
\nabla \phi_{atv}(x) = D^T \nabla F(Dx), \qquad
\nabla^2 \phi_{atv}(x) = D^T \nabla^2 F(Dx) D
$$</p>
<p>Hepsini bir araya koyarsak </p>
<p>$$
\nabla \psi(x) = 2(x-x_{cor}) + \mu D^T \nabla F(Dx)
$$</p>
<p>$$
\nabla^2 \psi(x) = 2 I  + \mu D^T \nabla^2 F(Dx) D
$$</p>
<p>Kodlamayı alttaki gibi yapabiliriz,</p>
<pre><code class="python">import pandas as pd
import scipy.sparse as sps
import scipy.sparse.linalg as slin

MU = 50.0
EPSILON = 0.001

ALPHA = 0.01;
BETA = 0.5;
MAXITERS = 100;
NTTOL = 1e-10;

n = len(xcor)
data = np.array([-1*np.ones(n), np.ones(n)])
diags = np.array([0, 1])
D = sps.spdiags(data, diags, n-1, n)

x = np.zeros((len(xcor),1))

for iter in range(MAXITERS):
   d = D.dot(x)
   val1 = np.dot((x-xcor).T,(x-xcor))
   val2 = np.sqrt(EPSILON**2 + np.power(d,2))
   val3 = EPSILON*np.ones((n-1,1))
   val = np.float(val1 + MU*np.sum(val2 - val3))
   grad1 = 2*(x-xcor)
   grad2 = MU*D.T.dot(d / np.sqrt(EPSILON**2 + d**2))
   grad = grad1 + grad2
   hess1 = 2*sps.eye(n)
   hess2 = EPSILON**2*(EPSILON**2+d**2)**(-3/2)
   hess2 = hess2.reshape((n-1))
   hess3 = sps.spdiags(hess2, 0, n-1, n-1)

   hess = hess1 + MU*hess3.dot(D).T.dot(D)
   v = slin.spsolve(-hess, grad)
   v = np.reshape(v, (n,1))
   lambdasqr = np.float(np.dot(-grad.T,v))
   if lambdasqr/2 &lt; NTTOL: break
   t = 1;
   while True:
      tmp1 = np.float(np.dot((x+t*v-xcor).T,(x+t*v-xcor)))
      tmp2 = MU*np.sum(np.sqrt(EPSILON**2+(D*(x+t*v))**2)-EPSILON*np.ones((n-1,1)))
      tmp3 = val - ALPHA*t*lambdasqr
      if tmp1 + tmp2 &lt; tmp3: break
      t = BETA*t

   x = x+t*v

plt.plot(range(n),xcor)
plt.plot(range(n),x,'r')
plt.savefig('func_60_tvd_03.png')
</code></pre>

<p><img alt="" src="func_60_tvd_03.png" /></p>
<p>Çok daha iyi bir gürültüsüz sonuç elde ettik, üstteki bu işlem çok daha
hızlı. </p>
<p>Kaynaklar</p>
<p>[1] <em>ROF and TV-L1 denoising with Primal-Dual algorithm</em>, 
    \url{https://github.com/znah/notebooks/blob/master/TV_denoise.ipynb}</p>
<p>[2] <em>An introduction to continuous optimization for imaging</em>, 
    <a href="https://hal.archives-ouvertes.fr/hal-01346507/document">https://hal.archives-ouvertes.fr/hal-01346507/document</a></p>
<p>[3] Afonso, <em>Fast Image Recovery Using Variable Splitting and Constrained Optimization</em>,
    \url{http://www.lx.it.pt/~mtf/Afonso_BioucasDias_Figueiredo_twocolumn_v7.pdf}</p>
<p>[4] Boyd, <em>Additional Exercises for Convex Optimization</em>
    \url{https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook_extra_exercises.pdf}</p>