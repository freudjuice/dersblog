\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Altgradyanlar (Subgradients)

Altgradyanlar aslýnda bir algoritma deðil, bir matematiksel kavram [1,
40:29], ve hem optimizasyon, hem analiz, hem de pratik baðlamda çok faydalý
bir kavram.  Hatýrlarsak dýþbükey ve türevi alýnabilir bir $f$ için

$$
f(y) \ge f(x) + \nabla f(x)^T (y-x)  \quad \forall x,y
$$

gerekli ve yeterli bir þart. Yani fonksiyonuma herhangi bir noktada
oluþturacaðým teðet eðri, yani lineer yaklaþýksallýk fonksiyonum için bir
global eksik / az tahmin edici (underestimator) olacaktýr, yani hep ondan
küçük kalacaktýr [1, 41:18]. 

Altgradyan nedir? Altgradyan üstteki gradyanin yerini alabilecek herhangi
bir $g$ vektörüdür, yerine alabilecek derken üstteki ifade her $y$ için
hala doðru olacak þekilde. Dýþbükey fonksiyon $f$'nin $x$ noktasýnda
altgradyaný herhangi bir $g \in \mathbb{R}^n$'dir öyle ki

$$
f(y) \ge f(x) + g^T (y-x) \quad \forall y
$$

olacak þekilde.

Teðet çizgi hakkýnda: görsel olaral hayal edersek kap þeklinde, yani
dýþbükey olan bir fonksiyona nerede teðet çizgi çekersem çekeyim
fonksiyonun kendisi hep o çizginin üstünde kalýr. Eðer fonksiyonum kap
olmasaydý, habire aþaðý yukarý inip çýkýyor olsaydý bir noktada o çizginin
altýna düþülebilirdi. Eðer $f$ türevi alýnabilir ise dýþbükey olmasýnýn
þartý üstteki ifadenin doðru olmasý.

Dýþbükey fonksiyonlar için 

1) $g$ her zaman mevcuttur (dýþbükey olmayan fonksiyonlar için $g$'nin
mevcudiyeti þart deðildir). Bu güzel bir özellik. 

2) Eðer $x$ noktasýnda $f$'in türevi alýnabilir ise, tek bir altgradyan
vardýr, o da türevin kendisidir [1, 43:12], $g = \nabla f(x)$.

Aslýnda \#2 kalemi dýþbükey olmayan bir $f$ için bile geçerli, eðer $g$
varsa. Bu durumlarda illa altgradyan olmasý gerekmiyor, hatta türevi
alýnabilir dýþbükey olmayan $f$ için bile $g$ olmayabiliyor. 

Dýþbükey olmayan (pürüzsüz) ve altgradyaný olmayan bir fonksiyon örneði
nedir? Alttaki,

\includegraphics[width=12em]{func_42_subgrad_01.png}

Bu fonksiyonun hiçbir yerde altgradyaný yok. Eðri üzerinde bir nokta
arýyorum öyle ki oradan geçen bir çizgi tüm fonksiyonu üstte
býraksýn.. böyle bir çizgi çizilemez. Altgradyan yok [1,
43:54]. Bazýlarýmýz itiraz edebilir, ``üstteki bir içbükey fonksiyon,
dýþbükeyin ters çevrilmiþ hali''. O zaman $x^3$ diyelim, pürüzsüz, ve
altgradyaný yok.

Altgradyaný mevcut fonksiyonlar görelim, mesela mutlak deðer fonksiyonu
$f(x) = |x|$.

\includegraphics[width=15em]{func_42_subgrad_02.png}

Altgradyanlar için farklý þartlarý görelim.

$x>0$ için tek bir altgradyan var, o da $g = 1$, yani fonksiyonun eðiminin
ta kendisi, eðim=1. Ayný þekilde $x<0$ için, o zaman $g=-1$. Bu sonuç
``eðer $f$'in $x$'te türevi alýnabilir ise o noktada $g=\nabla f$''
açýklamasý ile uyuyor. $x=0$ noktasý için birçok seçenek var, herhangi bir
$[-1,1]$ öðesi için, yani -1 ve +1 arasýndaki herhangi bir sayý olabilir,
çizgili noktalar seçeneklerden ikisi.

Boyut atlayalým, $f(x) = ||x||_2$ fonksiyonunu görelim, $x$'in L2
norm'u. Ýki boyutta [1, 45:51],

\includegraphics[width=15em]{func_42_subgrad_03.png}

Eðer $x \ne 0$ ise bu fonksiyonun türevi alýnabilir (yoksa alýnamaz, bir
yaygýn görüþe göre $x=0$'da problem yok, ama var) ve altgradyaný onun
mevcut gradyaný, $x / ||x||_2$. $x=0$ noktasýnda altgradyan $g$
$\{ z: ||z||_2 < 1\}$ kümesinin herhangi bir öðesi.

Þimdi $f(x) = ||x||_1$'e bakalým,

\includegraphics[width=15em]{func_42_subgrad_04.png}

Bu fonksiyonun $x=0$'da türevi alýnamaz, aynen tek boyutlu (mutlak deðer
fonksiyonu) versiyonunda olduðu gibi. Ayrýca bu fonksiyonun herhangi bir
eksende sýfýr deðer olduðu zamanda da türevi alýnamaz. Altgradyan için öðe öðe
yaklaþmak lazým, eðer bir öðe $x_i \ne 0$ ise $g_i = \sign(x_i)$, eðer
$x_i = 0$ ise $g_i \in [-1,+1]$.

En son örnek [1, 48:35] iki dýþbükey fonksiyonun maksimumu olaný, yani
$f(x) = \max \{f_1(x),f_2(x) \}$ ki $f_1,f_2$ dýþbükey ve türevi alýnabilir
olmak üzere, ve $f(x)$ bu iki fonksiyonun her $x$ noktasýnda $f_1(x)$ ve
$f_2(x)$'den hangisi büyükse o. Bu tür bir maks fonksiyonunun sonucunun
dýþbükey olduðunu önceki derslerden biliyoruz.

\includegraphics[width=15em]{func_42_subgrad_05.png}

Altgradyan yine farklý þartlara göre deðiþik oluyor. Eðer $f_1(x) > f_2(x)$
o zaman altgradyan özgün, $g = \nabla f_1(x)$. Eðer $f_2(x) > f_1(x)$ ise
altgradyan özgün, $g = \nabla f_2(x)$. 

Kabaca çizersek birbirlerini kesen $f_1$ ve $f_2$ düþünelim, 

\includegraphics[width=15em]{func_42_subgrad_06.png}

onlarýn maks halleri yeþil ile [çok kabaca benim eklediðim] çizgi, yani
kesiþmenin solunda $f_2$ saðýnda $f_1$. Tabii ki sol tarafta $f_2$ aktif o
zaman onun gradyaný geçerli, sað tarafta $f_1$. Kesiþme noktasý, $f_1=f_2$
ilginç, $g = \alpha \nabla f_1(x) + (1-\alpha) f_2(x)$, yani $f_1,f_2$'nin
herhangi bir dýþbükey kombinasyonu, ki iki üstteki resimde görülen iki
kesikli çizgiler bazý örnekler. 

Altdiferansiyel (Subdifferential)

Diþbükey $f$'in tüm altgradyanlarýna altdiferansiyel denir [1,
52:35]. Çoðunlukla kýsmi türev için kullanýlan ayný sembolle gösterilir,
$\partial$ ile.

$$
\partial f(x) = \{ 
g \in \mathbb{R}^n: \quad g, f\textrm{'in altgradyanýdýr}
\}
$$

Yani $x$ noktasýndaki tüm mümkün altgradyanlarýn kümesi altdiferansiyel
oluyor. 

1) $\partial f(x)$ kapalý ve dýþbükey bir kümedir. Ýþin ilginç tarafý bu
dýþbükey olmayan $f$'ler için bile geçerlidir. Niye olduðuna bakalým,
$\partial f(x)$ $x$'te $f(x)$'in tüm altgradyanlarýdýr. Diyelim ki
$g_1,g_2$ altgradyanlarý bu altdiferansiyel kümesinde, $g_1 \in \partial
f(x)$ ve $g_2 \in \partial f(x)$. Simdi $\alpha g_1 + (1-\alpha) g_2$
nerededir ona bakalým [1, 53:59]. Bu deðerin $y-x$ ile iþ çarpýmýný alýrsak
ve ona $f(x)$ eklersek acaba $f(y)$'den büyük bir deðer elde eder miyiz?

$$
(\alpha g_1 + (1-\alpha) g_2)^T (y-x) + f(x) \underbrace{\le}_{?} f(y) \forall y
\mlabel{1}
$$

Üsttekini ispatlayabilirsek $\partial f(x)$'in bir dýþbükey küme olduðunu
ispatlayabilirim, çünkü iki geçerli altgradyanin herhangi bir dýþbükey
kombinasyonunu almýþým ve hala küme içindeysem o küme dýþbükey küme
demektir. 

Alttaki iki ifadenin doðru olduðunu biliyoruz, 

$$
 g_1^T (y-x) + f(x) \le f(y) 
$$

$$
 g_2^T (y-x) + f(x) \le f(y) 
$$

Eðer iki üstteki ifadeyi $\alpha$ ile bir üstteki ifadeyi $1-\alpha$ ile
çarparsam ve toplarsam, basitleþtirme sonrasý (1)'i elde ederim. Ýspat
böylece tamamlanýr [1, 55:11].

Dikkat edersek $f$'nin dýþbükey olup olmadýðýndan bahsetmedik bile. 

2) Boþ Olmamak: eðer $f$ dýþbükey ise $\partial f(x)$ boþ deðildir.

3) Tek Altgradyan: önceden bahsettik ama eðer $f$ $x$ noktasýnda türevi
alýnabilir ise altdiferansiyelde tek bir öðe vardýr o da o noktadaki
gradyandýr, $\partial f(x) = \{ \nabla f(x) \}$. 

4) Üstteki özelliðe tersten bakarsak, eðer $\partial f(x) = \{ g \}$, yani
altdiferansiyelde tek bir öðe var ise, o zaman $f$ o noktada türevi
alýnabilir demektir ve o noktadaki gradyan $g$'dir. 

Altdiferansiyel Calculus

Altgradyanlarýn kendine has bir Calculus'u var, aynen gradyanlarý,
vs. içeren Çok Deðiþkenli Calculus'ta olduðu gibi [1, 59:53]. Bu
özellikler,

Ölçekleme: $\partial (af) = a \cdot \partial f$, $a$ sabit ise ve $a > 0$
olacak þekilde

Toplama: $\partial (f_1 + f_2) = \partial f_1 + \partial f_2$













[under review]

Doðrusal Bileþim: Eðer $g(x) = f(Ax + b)$ ise o zaman
$\partial g(x) = A^T \partial f(Ax + b)$. Bu altgradyanlar için bir tür
Zincirleme Kanunu gibi. Hatta eðer $f$ türevi alýnabilir ise, bu ifade tamý
tamýna Zincirleme Kanunu olurdu. 

Noktasal Sonlu Maksimum: Eðer $f(x) = \max_{i=1,..,m} f_i(x)$ ise, o zaman 

$$
\partial f(x) = conv \left( 
\bigcup_{i: f_i(x)=f(x)} \partial f_i(x)
\right)
$$

Biraz karmaþýk duruyor ama daha önce iki fonksiyon maksimumu üzerinden
gördüðümüz kavrama benziyor. Her noktada maks olan $f_i$'leri alýyoruz, ve
bu fonksiyonlarýn altgradyanlarýný hesaplýyoruz. Ama bu altgradyanlarýn
birleþimi her zaman bir dýþbükey küme oluþturmayabilir, ve
altdiferansiyelin bir dýþbükey küme olmasý gerekir, o zaman için elimizde
olan altgradyanlarýn $conv$ ile dýþbükey zarfýna (convex hull)
bakarýz. Yani sadece birleþim $\cup$ ile elde ettiðim kümeyi bir iþlemden
daha geçirerek onun dýþbükey küme halini alýyorum.

[atlandi, norm]

Niye Altgradyanlar?

1) Optimizasyon: Önemli bir sebep. Bir dýþbükey fonksiyonun altgradyanýný
hesaplamak her zaman mümkündür, o zaman her dýþbükey fonksiyonu minimize
edebilirim. Bazý durumlarda bu yavaþ olabilir ama en azýndan minimizasyon
mümkün olur.

2) Diþbükey Analizi: Her $f$ için, dýþbükey olsun olmasýn, 

$$
f(x^*) = \min_x f(x) \iff 0 \in \partial f(x^*)
$$

Yani $x^*$ bir minimize edicidir sadece ve sadece 0 $f$'in $x^*$ noktasýnda
bir altgradyaný ise. Bu özelliðe çoðunlukla ``altgradyan optimalliði'' adý
veriliyor. Ýspatý basit. Eðer $g$ vektörü $x^*$ noktasýndaki altgradyan
ise o zaman alttaki ifade her $y$ için doðrudur,

$$
f(y) \ge f(x^*) + 0^T (y-x^*) = f(x^*)
$$

$$
f(y) \ge f(x^*) \quad \forall y
$$

Üstteki ifade $x^*$ bir minimize edicidir diyor, o zaman sýfýr bir
altgradyandir. 

Bazen üstteki ifadenin dýþbükey olmayan fonksiyonlar için bile geçerli
olduðunu unutanlar oluyor. Bu her $f$ için doðru diyorum bazen bana
þaþýrmýþ þekilde bakýyorlar. Söylenen biraz sürpriz edici, evet. Ýkizlik ve
KKT þartlarý hakkýnda konuþurken benzer þaþýrtýcý ifadeler olacak. 

Tabii eklemek gerekir bazen dýþbükey olmayan fonksiyonlar için altgradyan
hesaplanamaz, ya da mevcut deðillerdir. Her problemi çözmek için bir yemek
tarifi deðil bu. Mesela baþta gördüðümüz içbükey fonksiyon,

\includegraphics[width=15em]{func_42_subgrad_01.png}

Altgradyaný yok (ama tabii minimize edicisi de yok). 

Altgradyanlar bir dýþbükey fonksiyon için her zaman mevcuttur [2], bazý aþýrý
durumlar haricinde, mesela gösterge fonksiyonu $I$'nin uç noktalarýnda
mevcut deðildir. 

Þimdi altgradyan yönteminin gücüne bir örnek görelim. Derslerimizin baþýnda
1. derece optimallik þartýný görmüþtük, 

$$
\min_x f(x) \quad \textrm{öyle ki} \quad x \in C
$$

problemini çözmek istiyoruz, diyelim $f$ dýþbükey ve türevi alýnabilir. Bu
problem için $x$'in çözüm olmasýnýn þartý 

$$
\nabla f(x)^T (y-x) \ge 0 \quad \forall y \in C
$$

eþitsizliðinin doðru olmasýdýr. Yani 1. derece minimallik gradyan sýfýrý
verir, o zaman herhangi bir $\nabla f(x)^T(y-x)$ yönünde adým atmak bizi her
zaman bu minimallikten uzaklaþtýrmalýdýr. Bu durum her olurlu $y \in C$
için doðru ise minimal yerdeyiz demektir.

Üsttekini altgradyan perspektifinden ispatlayabiliriz. Önce problemimizi
sýnýrsýz bir formatta tekrar tanýmlayacaðýz.  Sýnýrlamayý bir gösterge $I_C$
haline getirerek bunu yapabiliriz,

$$
\min_x f(x) + I_C(x)
$$

ki $I_C(x) = 0$ eðer $x$, $C$ kümesi içindeyse, dýþýndaysa sonsuzluk. Þimdi
üstteki fonksiyona altgradyan optimalliði uygulayalým, eðer üstteki
fonksiyonu minimize eden bir nokta varsa elimde, bunun tercümesi sýfýrýn o
noktada fonksiyonun altgradyaný olmasý. Fonksiyonun altgradyanini
hesaplayalým, kurallarýmýza göre iki dýþbükey fonksiyon toplamýnýn
altgradyani o fonksiyonlarýn ayrý ayrý altgradyanlarýnýn toplamý. $f$
dýþbükey, $I_C$ dýþbükey (çünkü $C$ kümesi dýþbükey küme). $f$ pürüzsüz, o
zaman $x$'te onun altgradyan kümesi sadece o noktadaki gradyan. $I_C$'nin
altgradyaný normal koni $N_C$. O zaman 

$$
0 \in \partial ( f(x) + I_C(x) ) = \nabla f(x) + N_C(x) 
$$

olmalý, ya da

$$
- \nabla f(x) \in N_C(x) 
$$

olmalý. Þimdi normal koniyi hatýrlayalým, tanýmý

$$
N_C(x) = \{ g \in \mathbb{R}^n: g^T x \ge g^T y \quad \forall y \in C
$$

buna göre iki üstteki $N_C$, $g=-\nabla f$ üzerinden

$$
-\nabla f(x)^T x \ge -\nabla f(x)^T y \quad \forall y \in C
$$

olarak açýlabilir. Ya da

$$
\nabla f(x)^T(y-x) \ge 0 \quad \forall y \in C
$$

Üstteki 1. derece optimallik þartýna benziyor zaten. $-\nabla f(x)$ üstteki
tanýmýn bir öðesidir, o zaman 0 altgradyan kümesinin öðesidir. 

Sonradan optimalliði tanýmlamanýn farklý bir yolunu göreceðiz. Sýnýrlama
ifadeleri olduðu zaman problemler daha az çetin / çözülür hale gelir,
problemler sýnýrsýz-sýnýrlý halde birbirine eþit þekilde tanýmlanabilirler,
ama sýnýrlý tanýmlarý çözmek daha kolay. KKT koþullarý burada devreye
girecek.  Yani her þeyi kritere týkmak, gösterge vs ile uðraþmak,
altgradyan almak yerine bu tür tanýmla çalýþmak daha rahat oluyor.

[atlandý]


















Kaynaklar

[1] Tibshirani, {\em Convex Optimization, Lecture Video 6}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}

[2] Tibshirani, {\em Convex Optimization, Lecture Video 7}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}

\end{document}



