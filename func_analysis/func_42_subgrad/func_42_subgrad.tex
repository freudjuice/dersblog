\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Altgradyanlar (Subgradients)

Altgradyanlar aslýnda bir algoritma deðil, bir matematiksel kavram [1,
40:29], ve hem optimizasyon, hem analiz, hem de pratik baðlamda çok faydalý
bir kavram.  Hatýrlarsak dýþbükey ve türevi alýnabilir bir $f$ için

$$
f(y) \ge f(x) + \nabla f(x)^T (y-x)  \quad \forall x,y
$$

gerekli ve yeterli bir þart. Yani fonksiyonuma herhangi bir noktada
oluþturacaðým teðet eðri, yani lineer yaklaþýksallýk fonksiyonum için bir
global eksik / az tahmin edici (underestimator) olacaktýr, yani hep ondan
küçük kalacaktýr [1, 41:18]. 

Altgradyan nedir? Altgradyan üstteki gradyanin yerini alabilecek herhangi
bir $g$ vektörüdür, yerine alabilecek derken üstteki ifade her $y$ için
hala doðru olacak þekilde. Dýþbükey fonksiyon $f$'nin $x$ noktasýnda
altgradyaný herhangi bir $g \in \mathbb{R}^n$'dir öyle ki

$$
f(y) \ge f(x) + g^T (y-x) \quad \forall y
$$

olacak þekilde.

Teðet çizgi hakkýnda: görsel olaral hayal edersek kap þeklinde, yani
dýþbükey olan bir fonksiyona nerede teðet çizgi çekersem çekeyim
fonksiyonun kendisi hep o çizginin üstünde kalýr. Eðer fonksiyonum kap
olmasaydý, habire aþaðý yukarý inip çýkýyor olsaydý bir noktada o çizginin
altýna düþülebilirdi. Eðer $f$ türevi alýnabilir ise dýþbükey olmasýnýn
þartý üstteki ifadenin doðru olmasý.

Dýþbükey fonksiyonlar için 

1) $g$ her zaman mevcuttur (dýþbükey olmayan fonksiyonlar için $g$'nin
mevcudiyeti þart deðildir). Bu güzel bir özellik. 

2) Eðer $x$ noktasýnda $f$'in türevi alýnabilir ise, tek bir altgradyan
vardýr, o da türevin kendisidir [1, 43:12], $g = \nabla f(x)$.

Aslýnda \#2 kalemi dýþbükey olmayan bir $f$ için bile geçerli, eðer $g$
varsa. Bu durumlarda illa altgradyan olmasý gerekmiyor, hatta türevi
alýnabilir dýþbükey olmayan $f$ için bile $g$ olmayabiliyor. 

Dýþbükey olmayan (pürüzsüz) ve altgradyaný olmayan bir fonksiyon örneði
nedir? Alttaki,

\includegraphics[width=12em]{func_42_subgrad_01.png}

Bu fonksiyonun hiçbir yerde altgradyaný yok. Eðri üzerinde bir nokta
arýyorum öyle ki oradan geçen bir çizgi tüm fonksiyonu üstte
býraksýn.. böyle bir çizgi çizilemez. Altgradyan yok [1,
43:54]. Bazýlarýmýz itiraz edebilir, ``üstteki bir içbükey fonksiyon,
dýþbükeyin ters çevrilmiþ hali''. O zaman $x^3$ diyelim, pürüzsüz, ve
altgradyaný yok.

Altgradyaný mevcut fonksiyonlar görelim, mesela mutlak deðer fonksiyonu
$f(x) = |x|$.

\includegraphics[width=15em]{func_42_subgrad_02.png}

Altgradyanlar için farklý þartlarý görelim.

$x>0$ için tek bir altgradyan var, o da $g = 1$, yani fonksiyonun eðiminin
ta kendisi, eðim=1. Ayný þekilde $x<0$ için, o zaman $g=-1$. Bu sonuç
``eðer $f$'in $x$'te türevi alýnabilir ise o noktada $g=\nabla f$''
açýklamasý ile uyuyor. $x=0$ noktasý için birçok seçenek var, herhangi bir
$[-1,1]$ öðesi için, yani -1 ve +1 arasýndaki herhangi bir sayý olabilir,
çizgili noktalar seçeneklerden ikisi.

Boyut atlayalým, $f(x) = ||x||_2$ fonksiyonunu görelim, $x$'in L2
norm'u. Ýki boyutta [1, 45:51],

\includegraphics[width=15em]{func_42_subgrad_03.png}

Eðer $x \ne 0$ ise bu fonksiyonun türevi alýnabilir (yoksa alýnamaz, bir
yaygýn görüþe göre $x=0$'da problem yok, ama var) ve altgradyaný onun
mevcut gradyaný, $x / ||x||_2$. $x=0$ noktasýnda altgradyan $g$
$\{ z: ||z||_2 < 1\}$ kümesinin herhangi bir öðesi.

Þimdi $f(x) = ||x||_1$'e bakalým,

\includegraphics[width=15em]{func_42_subgrad_04.png}

Bu fonksiyonun $x=0$'da türevi alýnamaz, aynen tek boyutlu (mutlak deðer
fonksiyonu) versiyonunda olduðu gibi. Ayrýca bu fonksiyonun herhangi bir
eksende sýfýr deðer olduðu zamanda da türevi alýnamaz. Altgradyan için öðe öðe
yaklaþmak lazým, eðer bir öðe $x_i \ne 0$ ise $g_i = \sign(x_i)$, eðer
$x_i = 0$ ise $g_i \in [-1,+1]$.

En son örnek [1, 48:35] iki dýþbükey fonksiyonun maksimumu olaný, yani
$f(x) = \max \{f_1(x),f_2(x) \}$ ki $f_1,f_2$ dýþbükey ve türevi alýnabilir
olmak üzere, ve $f(x)$ bu iki fonksiyonun her $x$ noktasýnda $f_1(x)$ ve
$f_2(x)$'den hangisi büyükse o. Bu tür bir maks fonksiyonunun sonucunun
dýþbükey olduðunu önceki derslerden biliyoruz.

\includegraphics[width=15em]{func_42_subgrad_05.png}

Altgradyan yine farklý þartlara göre deðiþik oluyor. Eðer $f_1(x) > f_2(x)$
o zaman altgradyan özgün, $g = \nabla f_1(x)$. Eðer $f_2(x) > f_1(x)$ ise
altgradyan özgün, $g = \nabla f_2(x)$. 

Kabaca çizersek birbirlerini kesen $f_1$ ve $f_2$ düþünelim, 

\includegraphics[width=15em]{func_42_subgrad_06.png}

onlarýn maks halleri yeþil ile [çok kabaca benim eklediðim] çizgi, yani
kesiþmenin solunda $f_2$ saðýnda $f_1$. Tabii ki sol tarafta $f_2$ aktif o
zaman onun gradyaný geçerli, sað tarafta $f_1$. Kesiþme noktasý, $f_1=f_2$
ilginç, $g = \alpha \nabla f_1(x) + (1-\alpha) f_2(x)$, yani $f_1,f_2$'nin
herhangi bir dýþbükey kombinasyonu, ki iki üstteki resimde görülen iki
kesikli çizgiler bazý örnekler. 

Altdiferansiyel (Subdifferential)

Diþbükey $f$'in tüm altgradyanlarýna altdiferansiyel denir [1,
52:35]. Çoðunlukla kýsmi türev için kullanýlan ayný sembolle gösterilir,
$\partial$ ile.

$$
\partial f(x) = \{ 
g \in \mathbb{R}^n: \quad g, f\textrm{'in altgradyanýdýr}
\}
$$

Yani $x$ noktasýndaki tüm mümkün altgradyanlarýn kümesi altdiferansiyel
oluyor. 

1) $\partial f(x)$ kapalý ve dýþbükey bir kümedir. Ýþin ilginç tarafý bu
dýþbükey olmayan $f$'ler için bile geçerlidir. Niye olduðuna bakalým,
$\partial f(x)$ $x$'te $f(x)$'in tüm altgradyanlarýdýr. Diyelim ki
$g_1,g_2$ altgradyanlarý bu altdiferansiyel kümesinde, $g_1 \in \partial
f(x)$ ve $g_2 \in \partial f(x)$. Simdi $\alpha g_1 + (1-\alpha) g_2$
nerededir ona bakalým [1, 53:59]. Bu deðerin $y-x$ ile iþ çarpýmýný alýrsak
ve ona $f(x)$ eklersek acaba $f(y)$'den büyük bir deðer elde eder miyiz?

$$
(\alpha g_1 + (1-\alpha) g_2)^T (y-x) + f(x) 
\underbrace{\le}_{?} f(y) \quad \forall y
\mlabel{1}
$$

Üsttekini ispatlayabilirsek $\partial f(x)$'in bir dýþbükey küme olduðunu
ispatlayabilirim, çünkü iki geçerli altgradyanýn herhangi bir dýþbükey
kombinasyonunu almýþým ve hala küme içindeysem o küme dýþbükey küme
demektir. 

Alttaki iki ifadenin doðru olduðunu biliyoruz, 

$$
 g_1^T (y-x) + f(x) \le f(y) 
$$

$$
 g_2^T (y-x) + f(x) \le f(y) 
$$

Eðer iki üstteki ifadeyi $\alpha$ ile bir üstteki ifadeyi $1-\alpha$ ile
çarparsam ve toplarsam, basitleþtirme sonrasý (1)'i elde ederim. Ýspat
böylece tamamlanýr [1, 55:11].

Dikkat edersek $f$'nin dýþbükey olup olmadýðýndan bahsetmedik bile. 

2) Boþ Olmamak: eðer $f$ dýþbükey ise $\partial f(x)$ boþ deðildir.

3) Tek Altgradyan: önceden bahsettik ama eðer $f$ $x$ noktasýnda türevi
alýnabilir ise altdiferansiyelde tek bir öðe vardýr o da o noktadaki
gradyandýr, $\partial f(x) = \{ \nabla f(x) \}$. 

4) Üstteki özelliðe tersten bakarsak, eðer $\partial f(x) = \{ g \}$, yani
altdiferansiyelde tek bir öðe var ise, o zaman $f$ o noktada türevi
alýnabilir demektir ve o noktadaki gradyan $g$'dir. 

[disbukey geometri baglantisi atlanti]

Altdiferansiyel Calculus

Altgradyanlarýn kendine has bir Calculus'u var, aynen gradyanlarý,
vs. içeren Çok Deðiþkenli Calculus'ta olduðu gibi [1, 59:53]. Birazdan
göstereceklerimizden daha fazlasý ama alttakiler en faydalý olanlarý [1,
1:00:00]. Diþbukey $f$ fonksiyonlarý için alttakiler geçerlidir,

Ölçekleme: $\partial (af) = a \cdot \partial f$, $a$ sabit ise ve $a > 0$
olacak þekilde

Toplama: $\partial (f_1 + f_2) = \partial f_1 + \partial f_2$

Doðrusal Bileþim: Eðer $g(x) = f(Ax + b)$ ise o zaman
$\partial g(x) = A^T \partial f(Ax + b)$. Bu altgradyanlar için bir tür
Zincirleme Kanunu gibi. Hatta eðer $f$ türevi alýnabilir ise, bu ifade tamý
tamýna Zincirleme Kanunu olurdu. 

Noktasal Sonlu Maksimum: Eðer $f(x) = \max_{i=1,..,m} f_i(x)$ ise, o zaman 

$$
\partial f(x) = conv \left( 
\bigcup_{i: f_i(x)=f(x)} \partial f_i(x)
\right)
$$

Biraz karmaþýk duruyor ama daha önce iki fonksiyon maksimumu üzerinden
gördüðümüz kavrama benziyor. Her noktada maks olan $f_i$'leri alýyoruz, ve
bu fonksiyonlarýn altgradyanlarýný hesaplýyoruz. Ama bu altgradyanlarýn
birleþimi her zaman bir dýþbükey küme oluþturmayabilir, ve
altdiferansiyelin bir dýþbükey küme olmasý gerekir, o zaman için elimizde
olan altgradyanlarýn $conv$ ile dýþbükey zarfýna (convex hull)
bakarýz. Yani sadece birleþim $\cup$ ile elde ettiðim kümeyi bir iþlemden
daha geçirerek onun dýþbükey küme halini alýyorum.

[atlandi, norm, 1:09:00]

Niye Altgradyanlar? 

1) Optimizasyon: Önemli bir sebep [1, 1:12:00]. Bir dýþbükey fonksiyonun
altgradyanýný hesaplamak her zaman mümkündür, o zaman her dýþbükey
fonksiyonu minimize edebilirim. Bazý durumlarda bu yavaþ olabilir ama en
azýndan minimizasyon mümkün olur.

2) Dýþbükey Analizi: Her $f$ için, dýþbükey olsun olmasýn, 

$$
f(x^*) = \min_x f(x) \iff 0 \in \partial f(x^*)
$$

Yani $x^*$ bir minimize edicidir sadece ve sadece 0 deðeri $f$'in $x^*$
noktasýnda bir altgradyaný ise. Bu özelliðe çoðunlukla ``altgradyan
optimalliði'' adý veriliyor. Ýspatý basit. Eðer $g$ vektörü $x^*$
noktasýndaki altgradyan ise o zaman alttaki ifade her $y$ için doðrudur,

$$
f(y) \ge f(x^*) + 0^T (y-x^*) = f(x^*)
$$

$$
f(y) \ge f(x^*) \quad \forall y
$$

Üstteki ifade $x^*$ bir minimize edicidir diyor, o zaman sýfýr bir
altgradyandýr. 

Bazen üstteki ifadenin dýþbükey olmayan fonksiyonlar için bile geçerli
olduðunu unutanlar oluyor [1:14:32]. Bu her $f$ için doðru diyorum bazen
bana þaþýrmýþ þekilde bakýyorlar. Söylenen biraz sürpriz edici,
evet. Ýkizlik ve KKT þartlarý hakkýnda konuþurken benzer þaþýrtýcý ifadeler
olacak.

Tabii eklemek gerekir bazen dýþbükey olmayan fonksiyonlar için altgradyan
hesaplanamaz, ya da mevcut deðillerdir. Her problemi çözmek için bir yemek
tarifi deðil bu. Mesela baþta gördüðümüz içbükey fonksiyon,

\includegraphics[width=15em]{func_42_subgrad_01.png}

Altgradyaný yok (ama tabii minimize edicisi de yok). 

Altgradyanlarla devam edelim [2, 01:11], onlar bir dýþbükey fonksiyonun
gradyaný kavramýnýn genelleþtirilmiþ hali idi. 

Bir dikkat edilmesi gereken durum var ama, altgradyanlar bir dýþbükey
fonksiyon için her zaman mevcuttur, ama bunu spesifik olarak ``taným
kümesinin nispeten iç bölgelerinde olacak þekilde'' diye vurgulamak
gerekir. Mesela gösterge fonksiyonu $I$'nin uç noktalarýnda mevcut deðildir.

Þimdi altgradyan yönteminin gücüne bir örnek görelim. Derslerimizin baþýnda
1. derece optimallik þartýný görmüþtük [2, 05:30],

$$
\min_x f(x) \quad \textrm{öyle ki} \quad x \in C
\mlabel{3}
$$

problemini çözmek istiyoruz, diyelim $f$ dýþbükey ve türevi alýnabilir. Bu
problem için $x$'in çözüm olmasýnýn þartý 

$$
\nabla f(x)^T (y-x) \ge 0 \quad \forall y \in C
$$

eþitsizliðinin doðru olmasýdýr. Yani 1. derece minimallik gradyan sýfýrý
verir, o zaman herhangi bir $\nabla f(x)^T(y-x)$ yönünde adým atmak bizi
her zaman bu minimallikten uzaklaþtýrmalýdýr. Bu durum her olurlu $y \in C$
için doðru ise minimal yerdeyiz demektir [2, 05:50]. Ya da þöyle anlatalým,
$x$ noktasýndayýz, $y$ noktasýna gitmeyi düþünüyoruz. O zaman $y-x$
vektörünü oluþturuyoruz, ve su soruyu soruyoruz, ``kriter fonksiyonunun
gradyaný ayný çizgi de mi?''. Eðer ayný yönde ise o yönde hareket etmek
kriter $f(x)$'i arttýrýr. Yani eðer gradyan her mümkün olurlu yön ile aþaðý
yukarý ayný yönü gösteriyorsa (azaltma / çoðaltma, -90/+90 derece
baðlamýnda) o zaman minimum noktadayýz demektir. 

\includegraphics[width=10em]{func_42_subgrad_07.png}

Ýþte bunu altgradyan perspektifinden ispatlayabiliriz [2, 06:33]. 

Üsttekini altgradyan perspektifinden ispatlayabiliriz. Önce problemimizi
sýnýrsýz bir formatta tekrar tanýmlayacaðýz.  Sýnýrlamayý bir gösterge $I_C$
haline getirerek bunu yapabiliriz,

$$
\min_x f(x) + I_C(x)
\mlabel{2}
$$

ki $I_C(x) = 0$ eðer $x$, $C$ kümesi içindeyse, dýþýndaysa sonsuzluk. Þimdi
üstteki fonksiyona altgradyan optimalliði uygulayalým, eðer üstteki
fonksiyonu minimize eden bir nokta varsa elimde, bunun tercümesi sýfýrýn o
noktada fonksiyonun altgradyaný olmasý. Fonksiyonun altgradyanýný
hesaplayalým, kurallarýmýza göre iki dýþbükey fonksiyon toplamýnýn
altgradyani o fonksiyonlarýn ayrý ayrý altgradyanlarýnýn toplamý. $f$
dýþbükey, $I_C$ dýþbükey (çünkü $C$ kümesi dýþbükey küme). $f$ pürüzsüz, o
zaman $x$'te onun altgradyan kümesi sadece o noktadaki gradyan. $I_C$'nin
altgradyaný normal koni $N_C$. O zaman 

$$
0 \in \partial ( f(x) + I_C(x) ) 
$$

$$
\iff 0 \in \nabla f(x) + N_C(x) 
$$


olmalý, ya da

$$
\iff - \nabla f(x) \in N_C(x) 
$$

olmalý. Þimdi normal koniyi hatýrlayalým, tanýmý

$$
N_C(x) = \{ g \in \mathbb{R}^n: g^T x \ge g^T y \quad \forall y \in C
$$

buna göre iki üstteki $N_C$, $g=-\nabla f$ üzerinden

$$
\iff -\nabla f(x)^T x \ge -\nabla f(x)^T y \quad \forall y \in C
$$

olarak açýlabilir. Ya da

$$
\iff \nabla f(x)^T(y-x) \ge 0 \quad \forall y \in C
$$

Üstteki 1. derece optimallik þartýna benziyor zaten. $-\nabla f(x)$ üstteki
tanýmýn bir öðesidir, o zaman 0 altgradyan kümesinin öðesidir. 

Ýþte gayet temiz bir þekilde optimallik ispatý yapmýþ olduk. Bu arada
sýnýrlama içeren optimizasiyon problemi için alttaki taným

$$
0 \in \partial f(x) + N_c
$$

ifadesi her nasýlsa tamamen genel, yani dýþbükey bir problem tanýmý için
gerekli ve yeterli bir þart çünkü hatýrlarsak bahsettik ki tüm dýþbükey
problemleri (2) ya da (3) formunda öne sürmek mümkün. Tabii üstteki formlea
iþ yapmak kolay deðildir, çünkü $N_C$ ile çalýþmak zor. Eðer $C$ çetrefil
bir küme ise, mesela

$$
C = \{ x: g_i(x) \le 0, Ax = b \}
$$

gibi, o zaman normal koniyi oluþturmak zor olacaktýr. Yani iki üstteki
tanýmýn her zaman faydalý olduðunu söyleyemeyiz, ama her dýþbükey problem
için gerekli ve yeterli þart olduðunu söyleyebiliyoruz.

Sonradan optimalliði tanýmlamanýn farklý bir yolunu göreceðiz. Sýnýrlama
ifadeleri olduðu zaman problemler daha az çetin / çözülür hale gelir,
problemler sýnýrsýz-sýnýrlý halde birbirine eþit þekilde tanýmlanabilirler,
ama sýnýrlý tanýmlarý çözmek daha kolay. KKT koþullarý burada devreye
girecek.  Yani her þeyi kritere týkmak, gösterge vs ile uðraþmak,
altgradyan almak yerine bu tür tanýmla çalýþmak daha rahat oluyor [2, 12:00].

Altgradyan optimalliðinin bazý diðer örneklerini görelim, mesela Lasso
için altgradyan optimalliði. Bazýlarýnýn bilebileceði üzere Lasso
problemini parametrize etmenin iki yolu vardýr, birisi katsayýlar üzerinde
bir L1 norm kýsýtlamasý tanýmlamak, diðeri ise alttaki gibi onu kritere
dahil etmek, 

$$
\min_\beta \frac{1}{2} || y - X \beta ||_2^2 + \lambda ||\beta||_1
$$

ki $\lambda \ge 0$. Altgradyan optimalliðinde sadece ve sadece alttaki þart
geçerliyse elimizde bir çözüm var diyebiliyoruz, bu þart, 

$$
0 \in \big( 
\frac{1}{2} || y - X \beta ||_2^2 + \lambda ||\beta||_1
\big)
$$

yani eðer 0 kriterimin altgradyan kümesinde ise. Üstteki altgradyanýn
uygulandýðý toplam iþaretinin iki tarafý da dýþbükey o zaman onlarý
altgradyanlarýn toplamý olarak açabilirim, ayrýca soldaki terim bir de
pürüzsüz olduðu için tek altgradyan normal gradyandýr,

$$
\iff 0 \in -X^T (y - X\beta) + \lambda \partial ||\beta||_1
$$

$$
\iff X^T (y - X\beta) = \lambda v 
\mlabel{4}
$$

herhangi bir $v \in \partial ||\beta||_1$ için. L1 norm'un altgradyaný için
daha önce gördüðümüz üzere bileþen bileþen bakmak gerekiyor, ve farklý
þartlara göre parçalý bir fonksiyon elde edeceðiz, 

$$
v_i \in
\left\{ \begin{array}{ll}
\{1\} & \textrm{eðer } \beta_i > 0 \\
\{-1\} & \textrm{eðer } \beta_i < 0 \\
{[} -1,+1{]} & \textrm{eger } \beta_i = 0 
\end{array} \right.
$$

Yeni öyle bir $\beta$ arýyorum ki herhangi bir $v$ vektörü için (4)'u
tatmin edecek ve bu $v$ geçerli bir altgradyan olacak, yani üstteki
þartlara uyacak. O zaman çözüme eriþmiþim demektir. Çözümü þu anda
vermiyoruz, bunlar çözüm için uyulmasý gereken optimallik þartlarý [2,
15:24].

Her $\beta_i$ için üstteki denklemin nasýl oluþacaðýný görmek istersek, ve
$X_1,..,X_p$ deðerleri $X$ matrisinin kolonlarý olacak þekilde

$$
\left[\begin{array}{ccc}
\uparrow & \uparrow & \\
&& \\
X_1 & X_2 & \dots \\
&& \\
\downarrow & \downarrow & 
\end{array}\right]^T
\left[\begin{array}{c}
y_1 \\ \vdots \\ y_p 
\end{array}\right] 
- 
\left[\begin{array}{ccc}
\uparrow & \uparrow & \\
&& \\
X_1 & X_2 & \dots \\
&& \\
\downarrow & \downarrow & 
\end{array}\right]
\left[\begin{array}{c}
\beta_1 \\ \vdots \\ \beta_p 
\end{array}\right]  =
\lambda
\left[\begin{array}{c}
v_1 \\ \vdots \\ v_p 
\end{array}\right] 
$$

O zaman bunu her $v_i$ olasýlýðý için yazarsak, $\beta_i$'in sýfýr olup
olmadýðý üzerinden bir parçalý fonksiyon ortaya çýkartabiliriz. Altgradyan
optimallik þartý,

$$
\left\{ \begin{array}{ll}
X_i^T (y-X\beta) = \lambda \cdot \sign(\beta_i) & \textrm{eger } \beta_i \ne 0 \\
| X_i^T (y-X\beta)  | \le \lambda  & \textrm{eger } \beta_i \ne 0 
\end{array} \right.
$$

haline geldi. Ýkinci satýrý nasýl elde ettik? Eðer $\beta_i=0$ ise bu bana
$\lambda v$ ifadesi $-\lambda$ ve $+\lambda$ arasýnda herhangi bir yerde
olabilir diyor (çünkü $v_i$ parçalý fonksiyonunda $\beta_i=0$ ise $v_i$ -1
ve +1 arasý herhangi bir deðer dedik), ve $-\lambda$ ve $+\lambda$ arasý
olma durumunu son satýrdaki mutlak deðer ifadesine tercüme edebiliriz.

Dikkat, üstteki ifade optimalliðe bakma / kontrol etmek için bir
yöntem. Birisi size bir vektör veriyor, sonra soruyor ``bu vektör Lasso
kriterine göre optimal midir?'' Öyle olup olmadýðýna bakmak için vektörün
her ögesine bakýyoruz, ve üstteki kontrolü iþletiyoruz. Eðer her öge
optimal ise evet diyoruz, tek bir öðe bile optimal deðilse hayýr diyoruz. 










Kaynaklar

[1] Tibshirani, {\em Convex Optimization, Lecture Video 6}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}

[2] Tibshirani, {\em Convex Optimization, Lecture Video 7}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}

\end{document}



