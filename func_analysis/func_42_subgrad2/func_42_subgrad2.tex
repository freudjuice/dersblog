\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Altgradyanlar (Subgradients) - 2

Bir dýþbükey kümesi üzerinden tanýmlý ama pürüzsüz olmayabilecek bir
dýþbükey fonksiyonu minimize etmek için yansýtýlan altgradyan (projected
subgradient) metotu adlý bir metot ta kullanýlabilir [1, 22:04].  

Diþbukey $f$'yi dýþbükey küme $C$ üzerinden optimize etmek için 

$$
\min_x f(x) \quad \textrm{oyle ki}, x \in C
$$

$$
x^{(k)} = P_C \left( x^{(k-1)} - t_k g_k^{(k-1)} \right)
$$

Bu metot normal altgradyan metotu gibi, tek fark parantez içinde görülen
altgradyan adýmý atýldýktan sonra elde edilen sonucun $C$ kümesine geri
yansýtýlmasý (projection), çünkü atýlan adým sonucunda olurlu bir sonuç
elde etmemiþ olabiliriz. 

Yakýnsama analizi normal altgraydan metotuna benziyor, bu metotla da benzer
yakýnsama garantisi elde edilebiliyor, yakýnsama oraný da buna dahil.

Yansýtma adýmý bazen zor olabilir, hangi durumlarda kolay olduðunun listesi
aþaðýda [1, 23:53]. Hangi kümelere yansýtmak kolaydýr?

1) Dogrusal goruntuler: $\{  Ax + b: x \in \mathbb{R}^n  \}$















Kaynaklar

[1] Tibshirani, {\em Convex Optimization, Lecture Video 8}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}



\end{document}












